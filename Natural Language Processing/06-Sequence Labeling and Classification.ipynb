{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mttcrn/AI-things/blob/main/Natural%20Language%20Processing/06%20-%20Sequence%20Labeling%20and%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giKsby3Lpdlp"
      },
      "source": [
        "# Sequence Labelling and Classification\n",
        "\n",
        "In this session we will first investigate Part-of-Speech (POS) tagging and Named-entity recognition (NER).\n",
        "- For this we will make use of the spaCy natural langauge processing API: https://spacy.io/\n",
        "- spaCy is an opensource API that provides state-of-the-art performance on sequence labeling tasks such as POS tagging and NER.\n",
        "- Parts of this tutorial are based on code from: https://medium.com/data-science/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApdPEmRJXkPN"
      },
      "source": [
        "**Optional for Colab users**\n",
        "\n",
        "Before starting, we can set up the connection with the Google Dive storage, to keep there our documents.\n",
        "Just execute the following passages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOtount4XkPN",
        "outputId": "616d71a9-14de-481d-ccb0-21578ab904fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwjVehAkXkPO"
      },
      "source": [
        "Make sure that the variable path contains the correct sequence of folders separate by a `'/'` to get to your lecture files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OgUv_TfNXkPO",
        "outputId": "4380907b-aac6-4795-8d8d-80a32d54a1d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/NLP/Practical_06__Sequential-Classifers-and-Labellers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path = 'Colab Notebooks/NLP/Practical_06__Sequential-Classifers-and-Labellers'\n",
        "\n",
        "os.chdir(f'/content/drive/MyDrive/{path}')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OgRPEb6pdlv"
      },
      "source": [
        "## Installing spaCy and downloading models\n",
        "\n",
        "First we need to check whether the spaCy library is installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3083U81cpdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e24189-1f18-4b5d-dd4e-c93358cd4ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ1xLIcHpdlw"
      },
      "source": [
        "Then we need to download pretrained models for use with spaCy. We will load models for both English and Italian:\n",
        "- The models are called 'en_core_web_sm' and 'it_core_news_sm', where the 'web'/'news' indicates what type of collection the model was trained on and the 'sm' at the end indicates that we are using the 'small' version of the models\n",
        "- Other models are available here: https://spacy.io/models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the model is not download automatically, uncomment the following code. It calls the python executable instructing it to run the module 'spacy', which in turn download the models. See discussion here: https://stackoverflow.com/questions/46148033/unable-to-load-en-from-spacy-in-jupyter-notebook"
      ],
      "metadata": {
        "id": "v05LKyQWZEuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyv-NpFbpdlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b899bf46-7291-4916-b63d-8404bff2ebca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting it-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m spacy download en_core_web_sm\n",
        "!{sys.executable} -m spacy download it_core_news_sm;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYRlbtvspdlx"
      },
      "source": [
        "We are now ready to import spacy and load a model. Let's start with the English model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KHrsza0pdlx"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp_model = en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy4K8dRApdlx"
      },
      "source": [
        "Consider the following piece of text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MGjLJU0pdlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a7817c-5ada-429c-a243-8a4d626f5650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
          ]
        }
      ],
      "source": [
        "text = 'Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.'\n",
        "# text = \"Good evening, London. Allow me first to apologize for this interruption. I do, like many of you, appreciate the comforts of everyday routine, the security of the familiar, the tranquillity of repetition. I enjoy them as much as any bloke. But in the spirit of commemoration, whereby those important events of the past, usually associated with someone's death or the end of some awful bloody struggle, are celebrated with a nice holiday, I thought we could mark this November the fifth, a day that is sadly no longer remembered, by taking some time out of our daily lives to sit down and have a little chat.\"\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_rCI0Hbpdly"
      },
      "source": [
        "Parse the text using the NLP engine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmpvXvjapdly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb95694-b986-4551-f155-35584a97d018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
          ]
        }
      ],
      "source": [
        "parsed_text = nlp_model(text)\n",
        "print(parsed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnXyGOx0pdlz"
      },
      "source": [
        "Did it do something? It looks like it has just output the same text.\n",
        "- Actually, yes. It has parsed the input and built its internal datastructure from it.\n",
        "- Note that the length of the parsed object is in words, not characters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbAOI2Mnpdlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87905275-dc1b-42b5-9b61-7b4757f47561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the original text is 229 chacacters\n",
            "The length of the parsed text is 43 words\n"
          ]
        }
      ],
      "source": [
        "print(f'The length of the original text is {len(text)} chacacters')\n",
        "print(f'The length of the parsed text is {len(parsed_text)} words')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, the parsed object is not a simple string. It is actually a Spacy **Document** object which implements a to_string() method. If requested access to the object, like in the case of just printing its value, Python automatically look for a to_string method, that's why if we just print the parsed object we get a string."
      ],
      "metadata": {
        "id": "agx17FP4dQth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(parsed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkOCiD3PdP8i",
        "outputId": "e2a8e1b9-c29f-45d7-e2fc-1ef790b08cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xImJ-i_Lpdlz"
      },
      "source": [
        "## Part-of-Speech Tagging\n",
        "\n",
        "While parsing the text, spaCy performs part-of-speech (POS) tagging.\n",
        "- We can see the POS tag for each token as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho4HEJTLpdlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79aac5b-f434-486b-f513-bf3c8fdf49ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Melbourne, 'PROPN'),\n",
              " (is, 'AUX'),\n",
              " (to, 'PART'),\n",
              " (re, 'VERB'),\n",
              " (-, 'VERB'),\n",
              " (enter, 'VERB'),\n",
              " (Stage, 'PROPN'),\n",
              " (3, 'NUM'),\n",
              " (lockdown, 'NOUN'),\n",
              " (after, 'ADP'),\n",
              " (a, 'DET'),\n",
              " (record, 'ADJ'),\n",
              " (increase, 'NOUN'),\n",
              " (in, 'ADP'),\n",
              " (cases, 'NOUN'),\n",
              " (., 'PUNCT'),\n",
              " (Victorian, 'ADJ'),\n",
              " (state, 'NOUN'),\n",
              " (premier, 'NOUN'),\n",
              " (Daniel, 'PROPN'),\n",
              " (Andrews, 'PROPN'),\n",
              " (said, 'VERB'),\n",
              " (there, 'PRON'),\n",
              " (was, 'VERB'),\n",
              " (“, 'PUNCT'),\n",
              " (simply, 'ADV'),\n",
              " (no, 'DET'),\n",
              " (alternative, 'NOUN'),\n",
              " (”, 'PUNCT'),\n",
              " (to, 'ADP'),\n",
              " (reimposing, 'VERB'),\n",
              " (stay, 'NOUN'),\n",
              " (at, 'ADP'),\n",
              " (home, 'NOUN'),\n",
              " (restrictions, 'NOUN'),\n",
              " (in, 'ADP'),\n",
              " (Australia, 'PROPN'),\n",
              " (’s, 'PART'),\n",
              " (second, 'ADV'),\n",
              " (-, 'PUNCT'),\n",
              " (biggest, 'ADJ'),\n",
              " (city, 'NOUN'),\n",
              " (., 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "[(w,w.pos_) for w in parsed_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFEzvleepdlz"
      },
      "source": [
        "Who remembers their grammar from high school? What do all those POS symbols mean?\n",
        "- You can find an explanation of the POS tags on this website https://spacy.io/api/annotation in the section \"Universal Part-of-speech Tags\"\n",
        "\n",
        "What can we do with POS tags?\n",
        "- Well, we could select all terms that have a certain tag, such as all adjectives:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kcjc28lpdl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c697cb-6545-4f0a-dcaf-0f32b427f113"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{record, Victorian, biggest}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "set(w for w in parsed_text if w.pos_=='ADJ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftw5HEYEpdl0"
      },
      "source": [
        "That was a little underwhelming.\n",
        "- Let's try it on Alice in Wonderland chapter 1 text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGRt3HF8pdl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3455e76-018d-4159-c350-745936ebf498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['afraid', 'best', 'brave', 'bright', 'certain', 'close', 'common', 'cool', 'curious', 'dark', 'deep', 'dreamy', 'dry', 'dull', 'empty', 'enough', 'fancy', 'few', 'first', 'fond', 'funny', 'glad', 'golden', 'good', 'grand', 'great', 'high', 'hot', 'hurt', 'ignorant', 'impossible', 'large', 'larger', 'late', 'legged', 'likely', 'little', 'long', 'loveliest', 'lovely', 'low', 'many', 'mixed', 'much', 'natural', 'nervous', 'nice', 'other', 'out', 'own', 'pine', 'pink', 'poor', 'red', 'remarkable', 'respectable', 'right', 'same', 'second', 'several', 'simple', 'sleepy', 'slippery', 'small', 'smaller', 'solid', 'stupid', 'such', 'sure', 'surprised', 'tart', 'tiny', 'tired', 'true', 'unpleasant', 'wild', 'wise', 'worth']\n"
          ]
        }
      ],
      "source": [
        "adjectives = sorted(set(w.text for w in nlp_model(open(\"docs/Alice_Chapter1.txt\", \"r\").read()) if w.pos_=='ADJ'))\n",
        "print(adjectives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pct1jNdEpdl0"
      },
      "source": [
        "You can see how descriptive a writer Lewis Carroll was!\n",
        "\n",
        "This leads us to one explanation as to why we might want to extract POS tags from text:\n",
        "- They can sometimes be useful for **extracting features** (often handcrafted ones) for certain text classification tasks (such as authorship identification).\n",
        "- This is particularly the case if only a small amount of training data is available.  \n",
        "- For example, in this article (https://medium.com/data-science/automatically-detect-covid-19-misinformation-f7ceca1dc1c7) hand-crafted features are extracted for classifying covid misinformation.\n",
        "\n",
        "Another reason why we might consider POS tagging is to **reduce ambiguity** in our bag-of-words representation by appending POS tags to word occurrences.\n",
        "- Consider the following two sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iO992Q-pdl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac28877-eae0-4688-81a8-6d96bef73fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I catch the train to and from work.      <-- 'train' is a NOUN\n",
            "I like to train at least 6 times a week. <-- 'train' is a VERB\n"
          ]
        }
      ],
      "source": [
        "ex1 = 'I catch the train to and from work.'       # This is Prof. Mark Carman speaking\n",
        "ex2 = 'I like to train at least 6 times a week.'  # This is Prof. Jacked Carman speaking\n",
        "\n",
        "print(ex1, '     <-- \\'train\\' is a', nlp_model(ex1)[3].pos_)\n",
        "print(ex2, '<-- \\'train\\' is a', nlp_model(ex2)[3].pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHlqof06pdl1"
      },
      "source": [
        "The second sentence has nothing to do with trains, despite containing the word 'train'!\n",
        "- We could deal with this issue by appending the POS tag to the observed literal to form vocabulary elements: train_NOUN, train_VERB\n",
        "\n",
        "A final reason why we might think about running POS tagging would be to extract proper nouns from the text, since they refer to real entities that are being discussed in it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW4TbHffpdl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9985b8a-c9c2-4003-c759-79ee167b5b2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Melbourne', 'Stage', 'Daniel', 'Andrews', 'Australia']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "[w.text for w in parsed_text if w.pos_=='PROPN']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDl1pPoSpdl1"
      },
      "source": [
        "Shortly though, we will talk about Entity-extraction, which is the task of identifying and categorising the entities discussed in the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDh0iS65pdl1"
      },
      "source": [
        "## Lemmatization\n",
        "\n",
        "While parsing, spaCy also performs lemmatization.\n",
        "- Lemmatization is the process of extracting the 'lemma' for each token, which is the canonical form of the word that would be found in the dictionary, (see https://en.wikipedia.org/wiki/Lemma_(morphology))\n",
        "- Basically, verbs converted to their root form, e.g.: **went, going, goes, gone => go**\n",
        "- And nouns are retuned to singular form: **kittens => kitten**\n",
        "- Lemmatization is a more complicated POS-aware process than stemming (https://en.wikipedia.org/wiki/Stemming). Stemmers simply apply a set of language-specific syntax rules to recover the stem of the word. For example, the word \"better\" is lemmatized to \"good\" if it is an adjective, or to \"better\" if it is a noun (i.e. \"Who bets something\"). A simple stemmer makes no distinction between these cases!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EevBrQRbpdl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3316e073-6926-4dae-9f95-c93e2cc53f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Melbourne, 'Melbourne'),\n",
              " (is, 'be'),\n",
              " (to, 'to'),\n",
              " (re, 're'),\n",
              " (-, '-'),\n",
              " (enter, 'enter'),\n",
              " (Stage, 'Stage'),\n",
              " (3, '3'),\n",
              " (lockdown, 'lockdown'),\n",
              " (after, 'after'),\n",
              " (a, 'a'),\n",
              " (record, 'record'),\n",
              " (increase, 'increase'),\n",
              " (in, 'in'),\n",
              " (cases, 'case'),\n",
              " (., '.'),\n",
              " (Victorian, 'victorian'),\n",
              " (state, 'state'),\n",
              " (premier, 'premier'),\n",
              " (Daniel, 'Daniel'),\n",
              " (Andrews, 'Andrews'),\n",
              " (said, 'say'),\n",
              " (there, 'there'),\n",
              " (was, 'be'),\n",
              " (“, '\"'),\n",
              " (simply, 'simply'),\n",
              " (no, 'no'),\n",
              " (alternative, 'alternative'),\n",
              " (”, '\"'),\n",
              " (to, 'to'),\n",
              " (reimposing, 'reimpose'),\n",
              " (stay, 'stay'),\n",
              " (at, 'at'),\n",
              " (home, 'home'),\n",
              " (restrictions, 'restriction'),\n",
              " (in, 'in'),\n",
              " (Australia, 'Australia'),\n",
              " (’s, '’s'),\n",
              " (second, 'second'),\n",
              " (-, '-'),\n",
              " (biggest, 'big'),\n",
              " (city, 'city'),\n",
              " (., '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "[(x, x.lemma_) for x in parsed_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEIoq1RFpdl1"
      },
      "source": [
        "Why would one want to perfom lemmatization? -- Or stemming for that matter?\n",
        "- to **reduce the vocabulary size** and thereby generalise the representation. -- This used to be very important for improving performance of search engine performance (better similarity measures between documents) and also classifiers on small datasets, (before word embeddings came along).\n",
        "- to **look-up information** about the word in a dictionary/ontology, such as WordNet (https://en.wikipedia.org/wiki/WordNet). This used to be an important way to compute semantic similarity between words, but again, word embeddngs probably do a better job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBQ7f0tpdl2"
      },
      "source": [
        "## Dependency Parsing\n",
        "\n",
        "Tradititonally in Natural Language Processing, text is processed in a pipeline that first tokenizes, then POS tags, lemmatizes and finaly dependency parses a piece of text.\n",
        "- The idea with dependency parsing is to determine what function each of the word instances is fulfilling in the sentence.\n",
        "- What is the subject and object of the sentence?\n",
        "- Which noun is each adjective referring to?\n",
        "\n",
        "So while parsing the text, the spaCy model also generates a **dependency parse tree**, which can be displayed using 'displacy':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbz57hc5pdl2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "bec83c49-ab20-4ef8-8e3d-b4734df8184b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"95a73898f84740c18d2535fa38b30eb0-0\" class=\"displacy\" width=\"6525\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Melbourne</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">re-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">enter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Stage</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">3</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">lockdown</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">after</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">record</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">increase</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">cases.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">Victorian</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">state</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">premier</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">Daniel</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">Andrews</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">said</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">there</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">was “</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">simply</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">alternative”</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">reimposing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">stay</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">home</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">restrictions</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">Australia</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">’s</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">second-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">biggest</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">city.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M565.0,354.0 L573.0,342.0 557.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,354.0 L753.0,342.0 737.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-7\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,177.0 1965.0,177.0 1965.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-11\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2135.0,354.0 L2143.0,342.0 2127.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-12\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2310.0,354.0 L2318.0,342.0 2302.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-13\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,177.0 2840.0,177.0 2840.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,354.0 L2512,342.0 2528,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-14\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,264.5 2835.0,264.5 2835.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-15\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,177.0 3190.0,177.0 3190.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-16\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,264.5 3185.0,264.5 3185.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-17\" stroke-width=\"2px\" d=\"M3220,352.0 C3220,264.5 3360.0,264.5 3360.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,354.0 L3212,342.0 3228,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-18\" stroke-width=\"2px\" d=\"M3570,352.0 C3570,264.5 3710.0,264.5 3710.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">expl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,354.0 L3562,342.0 3578,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-19\" stroke-width=\"2px\" d=\"M3395,352.0 C3395,177.0 3715.0,177.0 3715.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3715.0,354.0 L3723.0,342.0 3707.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-20\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,264.5 3885.0,264.5 3885.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3885.0,354.0 L3893.0,342.0 3877.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-21\" stroke-width=\"2px\" d=\"M4095,352.0 C4095,264.5 4235.0,264.5 4235.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4095,354.0 L4087,342.0 4103,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-22\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,177.0 4240.0,177.0 4240.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4240.0,354.0 L4248.0,342.0 4232.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-23\" stroke-width=\"2px\" d=\"M4270,352.0 C4270,264.5 4410.0,264.5 4410.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4410.0,354.0 L4418.0,342.0 4402.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-24\" stroke-width=\"2px\" d=\"M4445,352.0 C4445,264.5 4585.0,264.5 4585.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4585.0,354.0 L4593.0,342.0 4577.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-25\" stroke-width=\"2px\" d=\"M4620,352.0 C4620,264.5 4760.0,264.5 4760.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4760.0,354.0 L4768.0,342.0 4752.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-26\" stroke-width=\"2px\" d=\"M4795,352.0 C4795,264.5 4935.0,264.5 4935.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4935.0,354.0 L4943.0,342.0 4927.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-27\" stroke-width=\"2px\" d=\"M5145,352.0 C5145,264.5 5285.0,264.5 5285.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5145,354.0 L5137,342.0 5153,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-28\" stroke-width=\"2px\" d=\"M4970,352.0 C4970,177.0 5290.0,177.0 5290.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5290.0,354.0 L5298.0,342.0 5282.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-29\" stroke-width=\"2px\" d=\"M5320,352.0 C5320,264.5 5460.0,264.5 5460.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5460.0,354.0 L5468.0,342.0 5452.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-30\" stroke-width=\"2px\" d=\"M5670,352.0 C5670,177.0 6340.0,177.0 6340.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,354.0 L5662,342.0 5678,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-31\" stroke-width=\"2px\" d=\"M5670,352.0 C5670,264.5 5810.0,264.5 5810.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5810.0,354.0 L5818.0,342.0 5802.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-32\" stroke-width=\"2px\" d=\"M6020,352.0 C6020,264.5 6160.0,264.5 6160.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6020,354.0 L6012,342.0 6028,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-33\" stroke-width=\"2px\" d=\"M6195,352.0 C6195,264.5 6335.0,264.5 6335.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6195,354.0 L6187,342.0 6203,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95a73898f84740c18d2535fa38b30eb0-0-34\" stroke-width=\"2px\" d=\"M5495,352.0 C5495,89.5 6345.0,89.5 6345.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95a73898f84740c18d2535fa38b30eb0-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6345.0,354.0 L6353.0,342.0 6337.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "displacy.render(parsed_text, jupyter=True, style='dep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quwWOjbOpdl3"
      },
      "source": [
        "Such dependency trees are interesting for understanding and visualising language (particularly for linguists) and could possibly be used for some downstream tasks (say checking ambiguity in legal documents).  \n",
        "\n",
        "Consider the sentences:\n",
        "- *The girl saw a man carrying a telescope.*\n",
        "- *The girl saw a man with a telescope.*\n",
        "\n",
        "Who had the telescope?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AxJLNswpdl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "0211fb54-bbbf-4dfe-9f9c-21caea307d48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"80261c2c60e840bb838386a1a3588bae-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">girl</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">saw</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">man</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">carrying</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">telescope.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-80261c2c60e840bb838386a1a3588bae-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-80261c2c60e840bb838386a1a3588bae-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(nlp_model('The girl saw a man carrying a telescope.'),jupyter=True,style='dep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7abgGOdwpdl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "78ec53fb-5820-4c4f-8e37-2d7bc61583a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"51b1d187525a47198469c410c57dd497-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">girl</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">saw</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">man</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">telescope.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-51b1d187525a47198469c410c57dd497-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-51b1d187525a47198469c410c57dd497-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(nlp_model('The girl saw a man with a telescope.'),jupyter=True,style='dep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fIZq6zIhPbk"
      },
      "source": [
        "The second sentence is ambiguous: The girl may have made use of her telescope or the man may have been using the girl's telescope...\n",
        "- Language is full of such ambiguities which we as humans naturally deal with using our prior knowledge and abilty to construct mental models of the situations described.\n",
        "- This process is not without its biases:\n",
        "  - *The doctor went over to talk to the nurse. She told him that she had just given the patient 5mg of Vicodin and the child had started convulsing. He listened attentively as she explained what had happened. The doctor was worried that the patient should not be given any more painkillers. The nurse told the doctor not to worry, that the patient was in good hands, and that he would let her know immediately if the child's condition changed.*\n",
        "  - What gender are the doctor and the nurse?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uE1efbqpdl3"
      },
      "source": [
        "## Extracting Entities\n",
        "\n",
        "A more important output than the depency parse, from a text mining perspective, is the list of named-entities present in the text\n",
        "- **named entities** are objects in the real world, e.g. persons, products, organizations, locations, etc.\n",
        "  - see https://en.wikipedia.org/wiki/Named_entity\n",
        "- if spacy has found any named entities while parsing the text, we can access them as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irYwH5WVpdl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14967fda-e5dd-42d0-8add-191788c59fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Melbourne, 3, Victorian, Daniel Andrews, Australia, second)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "parsed_text.ents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6krbXmpdl3"
      },
      "source": [
        "Note that the entities are not single word tokens but short sequences of words: 'Stage 3' and 'Daniel Andrews'.\n",
        "\n",
        "Not only does spacy extract the entities, but also categorises them based on their type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXA2FRzXpdl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a323cb-a6d7-4728-dc5c-0e801a3fa54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Melbourne', 'GPE'), ('3', 'CARDINAL'), ('Victorian', 'NORP'), ('Daniel Andrews', 'PERSON'), ('Australia', 'GPE'), ('second', 'ORDINAL')]\n"
          ]
        }
      ],
      "source": [
        "print([(ent.text, ent.label_) for ent in parsed_text.ents])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyp09Uelpdl4"
      },
      "source": [
        "The city and country locations have been labeled 'GPE' for 'geopolitical entity', while the Premier of Victoria has been correctly identified as a person.\n",
        "- Here is the list of all entity types that spaCy looks for: https://spacy.io/api/annotation#section-named-entities\n",
        "\n",
        "Internally, the output of the Named Entity Recogniser is a sequence annotated with entities using inside-outside-beginning encoding:\n",
        "- see https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n",
        "- We can print out this labeling as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E1H-RM6pdl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1f59da-6271-4b88-8705-e170f05af8ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Melbourne, 'B', 'GPE'),\n",
              " (is, 'O', ''),\n",
              " (to, 'O', ''),\n",
              " (re, 'O', ''),\n",
              " (-, 'O', ''),\n",
              " (enter, 'O', ''),\n",
              " (Stage, 'O', ''),\n",
              " (3, 'B', 'CARDINAL'),\n",
              " (lockdown, 'O', ''),\n",
              " (after, 'O', ''),\n",
              " (a, 'O', ''),\n",
              " (record, 'O', ''),\n",
              " (increase, 'O', ''),\n",
              " (in, 'O', ''),\n",
              " (cases, 'O', ''),\n",
              " (., 'O', ''),\n",
              " (Victorian, 'B', 'NORP'),\n",
              " (state, 'O', ''),\n",
              " (premier, 'O', ''),\n",
              " (Daniel, 'B', 'PERSON'),\n",
              " (Andrews, 'I', 'PERSON'),\n",
              " (said, 'O', ''),\n",
              " (there, 'O', ''),\n",
              " (was, 'O', ''),\n",
              " (“, 'O', ''),\n",
              " (simply, 'O', ''),\n",
              " (no, 'O', ''),\n",
              " (alternative, 'O', ''),\n",
              " (”, 'O', ''),\n",
              " (to, 'O', ''),\n",
              " (reimposing, 'O', ''),\n",
              " (stay, 'O', ''),\n",
              " (at, 'O', ''),\n",
              " (home, 'O', ''),\n",
              " (restrictions, 'O', ''),\n",
              " (in, 'O', ''),\n",
              " (Australia, 'B', 'GPE'),\n",
              " (’s, 'O', ''),\n",
              " (second, 'B', 'ORDINAL'),\n",
              " (-, 'O', ''),\n",
              " (biggest, 'O', ''),\n",
              " (city, 'O', ''),\n",
              " (., 'O', '')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "[(X, X.ent_iob_, X.ent_type_) for X in parsed_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10tU8n44pdl4"
      },
      "source": [
        "The above format is a bit hard to read though, so spaCy also provides a far more natural visualisation of the tags:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PmUl2y5pdl4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "631929e8-75b3-438a-e99d-2d384aeb971d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Melbourne\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " is to re-enter Stage \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    3\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " lockdown after a record increase in cases. \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Victorian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " state premier \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Daniel Andrews\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said there was “simply no alternative” to reimposing stay at home restrictions in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Australia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "’s \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              "-biggest city.</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "displacy.render(parsed_text, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS1PK7ifpdl5"
      },
      "source": [
        "## Extracting entities from a web document\n",
        "\n",
        "Now that we know how to perform entity recognition on text, let's apply it to a full document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pY-nN0Zpdl5"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.bbc.com/news/world-latin-america-53319517'\n",
        "#url = 'https://en.wikipedia.org/wiki/Apple_(disambiguation)'\n",
        "\n",
        "import requests\n",
        "html_doc = requests.get(url).text\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRe5AUvCpdl5"
      },
      "source": [
        "Now lets extract the title and paragraph text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5YGoQISpdl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52da45b6-0202-4b4b-9bb9-be82e2dd8228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coronavirus: Brazil's President Bolsonaro tests positive\n",
            "\n",
            "Brazil's President Jair Bolsonaro has tested positive for coronavirus.\n",
            "He took the test, his fourth, on Monday after developing symptoms, including a high temperature.\n",
            "Mr Bolsonaro has repeatedly played down risks of what he has called the \"little flu\", saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.\n",
            "Brazil has the second-highest number of Covid-19 cases and deaths in the world, after the US. \n",
            "He made the announcement in a TV interview on Tuesday, saying the fever he had been experiencing had gone down and that he felt \"very well\".\n",
            "Mr Bolsonaro said that he had started experiencing symptoms on Sunday. He said he had had a high temperature, a cough and had felt unwell. \n",
            "He added that on Monday he had felt worse, which prompted him to take the coronavirus test.\n",
            "Mr Bolsonaro is in a higher-risk group because of his age, 65.\n",
            "He said he was taking hydroxychloroquine - championed by US President Donald Trump - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.\n",
            "Contact tracing and tests will be carried out for the people Mr Bolsonaro has met recently.\n",
            "His previous three tests for the virus all came back negative.\n",
            "The executive director of the World Health Organization, Dr Mike Ryan, wished President Bolsonaro \"a speedy and full recovery from this disease\", adding: \"I think the message to us all is: we are vulnerable to this virus.\"\n",
            "Back in April, Mr Bolsonaro said that even if infected, he would \"not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold\".\n",
            "The number of Covid-19-related deaths and infections - at that time under 3,000 and 40,000 - has since soared.\n",
            "Despite this, President Bolsonaro has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.\n",
            "His other comments on the virus include:\n",
            "He has since continued to rail against measures that he deems \"dictatorial\" such as the closing beaches or requirements to wear face coverings. \n",
            "On Monday, he made further changes to a law that would require Brazilians to wear masks in public.\n",
            "He has attended a number of public events without a mask, even when local rules required him to wear one.\n",
            "On Sunday, Foreign Minister Ernesto Araújo posted a photo on social media showing himself with President Bolsonaro and others attending an Independence Day celebration at the US embassy in Brasilia. \n",
            "None of those in the photo is wearing a mask or observing social distancing.\n",
            "The US embassy said that the ambassador had had lunch with Mr Bolsonaro and others on 4 July. It added that the ambassador had no symptoms but that he would undergo testing.\n",
            "The ambassador had earlier tweeted a picture of himself with President Bolsonaro.\n",
            "For so long, Jair Bolsonaro has tried to brush off this virus - the irony that he has now caught it has not been missed in Brazil. \n",
            "His detractors - of which he has many - have weighed in, calling this karma - that Jair Bolsonaro invited this to happen. \n",
            "There was even a column in one of the biggest newspapers, Folha de São Paulo, entitled \"Why I'm Cheering for Bolsonaro to Die\" - this is how divided, how toxic  the political picture is here in Brazil as the pandemic takes hold. \n",
            "But the fact is, Bolsonaro joins the nearly 1.7 million Brazilians who've contracted Covid-19. They're scary numbers and Brazil is a country in trouble, where coronavirus is spreading fast. \n",
            "Will Jair Bolsonaro get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. \n",
            "Infections in Brazil and Latin America as a whole took a while to take hold but then started to rise, initially for Brazil in its Amazonas region but then more starkly in Rio de Janeiro and São Paulo.\n",
            "Brazil became only the second country to pass one million cases on 20 June and has continued to rise, passing 1.5 million. Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.\n",
            "Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and São Paulo have reopened bars and restaurants in the past week.\n",
            "Two health ministers - both doctors - have left their posts after disagreements with the president.\n",
            "One ray of hope though is Brazil's renowned expertise in vaccines. Two major vaccine tests, in partnership with AstraZeneca and Sinovac, are to begin final phase testing on thousands of Brazilian volunteers.\n",
            "Copyright 2025 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.\n",
            " \n"
          ]
        }
      ],
      "source": [
        "title = parsed_doc.find('title').text\n",
        "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
        "\n",
        "# Combine the title and paragraphs into a single text:\n",
        "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
        "print(article_text)\n",
        "\n",
        "#article_text = parsed_doc.get_text()\n",
        "#print(article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_dqist0pdl5"
      },
      "source": [
        "Parse the article to identify the entities and display them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMTsfAhYpdl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d75d8fc6-9cca-4572-c70a-3291ed00e958"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " tests positive<br><br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tested positive for coronavirus.<br>He took the test, his \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fourth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              ", on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " after developing symptoms, including a high temperature.<br>Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has repeatedly played down risks of what he has called the &quot;little flu&quot;, saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.<br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " has the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              "-highest number of Covid-19 cases and deaths in the world, after the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br>He made the announcement in a TV interview on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tuesday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", saying the fever he had been experiencing had gone down and that he felt &quot;very well&quot;.<br>Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that he had started experiencing symptoms on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". He said he had had a high temperature, a cough and had felt unwell. <br>He added that on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " he had felt worse, which prompted him to take the coronavirus test.<br>Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is in a higher-risk group because of \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    his age, 65\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br>He said he was taking hydroxychloroquine - championed by \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donald Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.<br>Contact tracing and tests will be carried out for the people Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has met recently.<br>His previous \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    three\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " tests for the virus all came back negative.<br>The executive director of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the World Health Organization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Dr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mike Ryan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", wished President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " &quot;a speedy and full recovery from this disease&quot;, adding: &quot;I think the message to us all is: we are vulnerable to this virus.&quot;<br>Back in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that even if infected, he would &quot;not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold&quot;.<br>The number of Covid-19-related deaths and infections - at that time \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    under 3,000 and 40,000 -\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
              "</mark>\n",
              " has since soared.<br>Despite this, President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.<br>His other comments on the virus include:<br>He has since continued to rail against measures that he deems &quot;dictatorial&quot; such as the closing beaches or requirements to wear face coverings. <br>On \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", he made further changes to a law that would require \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilians\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " to wear masks in public.<br>He has attended a number of public events without a mask, even when local rules required him to wear one.<br>On \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Foreign Minister \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ernesto Araújo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " posted a photo on social media showing himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others attending an \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Independence Day\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " celebration at the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br>None of those in the photo is wearing a mask or observing social distancing.<br>The \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy said that the ambassador had had lunch with Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    4 July\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". It added that the ambassador had no symptoms but that he would undergo testing.<br>The ambassador had earlier tweeted a picture of himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".<br>For so long, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tried to brush off this virus - the irony that he has now caught it has not been missed in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br>His detractors - of which he has many - have weighed in, calling this karma - that \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " invited this to happen. <br>There was even a column in one of the biggest newspapers, \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Folha de São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", entitled &quot;Why I'm Cheering for Bolsonaro to Die&quot; - this is how divided, how toxic  the political picture is here in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " as the pandemic takes hold. <br>But the fact is, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " joins the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 1.7 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilians\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " who've contracted Covid-19. They're scary numbers and \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " is a country in trouble, where coronavirus is spreading fast. <br>\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Will Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. <br>Infections in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Latin America\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " as a whole took a while to take hold but then started to rise, initially for \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " in its \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amazonas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " region but then more starkly in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rio de Janeiro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".<br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " became only the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " country to pass \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    one million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " cases on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    20 June\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " and has continued to rise, passing \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1.5 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              ". Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.<br>Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " have reopened bars and restaurants in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the past week\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br>\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " health ministers - both doctors - have left their posts after disagreements with the president.<br>\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " ray of hope though is \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s renowned expertise in vaccines. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " major vaccine tests, in partnership with \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    AstraZeneca and Sinovac\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", are to begin final phase testing on \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    thousands\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " volunteers.<br>Copyright \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    BBC\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". All rights reserved.  The \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    BBC\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is not responsible for the content of external sites. Read about our approach to external linking.<br> </div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "parsed_article = nlp_model(article_text)\n",
        "displacy.render(parsed_article,jupyter=True,style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I8_zJQrpdl6"
      },
      "source": [
        "What do you think? Did it work?\n",
        "\n",
        "Let's have a bit of a better look at the entities found\n",
        "- List all the distinct entities found in the article, sorted alphabetically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SakcaXuypdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815dc21d-c48f-47bb-ca22-d2d64f16025e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.5 million',\n",
              " '20 June',\n",
              " '2025',\n",
              " '4 July',\n",
              " 'Amazonas',\n",
              " 'April',\n",
              " 'AstraZeneca and Sinovac',\n",
              " 'BBC',\n",
              " 'Bolsonaro',\n",
              " 'Brasilia',\n",
              " 'Brazil',\n",
              " 'Brazilian',\n",
              " 'Brazilians',\n",
              " 'Donald Trump',\n",
              " 'Ernesto Araújo',\n",
              " 'Folha de São Paulo',\n",
              " 'Independence Day',\n",
              " 'Jair Bolsonaro',\n",
              " 'Latin America',\n",
              " 'Mike Ryan',\n",
              " 'Monday',\n",
              " 'One',\n",
              " 'Rio de Janeiro',\n",
              " 'Sunday',\n",
              " 'São Paulo',\n",
              " 'Tuesday',\n",
              " 'Two',\n",
              " 'US',\n",
              " 'Will Jair Bolsonaro',\n",
              " 'fourth',\n",
              " 'his age, 65',\n",
              " 'nearly 1.7 million',\n",
              " 'one million',\n",
              " 'second',\n",
              " 'the World Health Organization',\n",
              " 'the past week',\n",
              " 'thousands',\n",
              " 'three',\n",
              " 'under 3,000 and 40,000 -']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "sorted(set(x.text for x in parsed_article.ents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyGeLXs8pdl6"
      },
      "source": [
        "We can count the number of times each **entity type** occurs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcmsbiUkpdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b2f89-4408-4f8e-a9f8-c74ef4b3924c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'GPE': 16,\n",
              "         'PERSON': 21,\n",
              "         'ORDINAL': 3,\n",
              "         'DATE': 12,\n",
              "         'CARDINAL': 8,\n",
              "         'ORG': 6,\n",
              "         'QUANTITY': 1,\n",
              "         'NORP': 3,\n",
              "         'EVENT': 1,\n",
              "         'LOC': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = [x.label_ for x in parsed_article.ents]\n",
        "Counter(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb3g9y5Kpdl6"
      },
      "source": [
        "We can also count the number of times each **entity name** occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPdOsoiApdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0863959a-d825-4533-b369-a6b5cf0e2f24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bolsonaro', 12),\n",
              " ('Brazil', 10),\n",
              " ('US', 4),\n",
              " ('Jair Bolsonaro', 3),\n",
              " ('Monday', 3),\n",
              " ('second', 2),\n",
              " ('Sunday', 2),\n",
              " ('Brazilians', 2),\n",
              " ('São Paulo', 2),\n",
              " ('Two', 2),\n",
              " ('BBC', 2),\n",
              " ('fourth', 1),\n",
              " ('Tuesday', 1),\n",
              " ('his age, 65', 1),\n",
              " ('Donald Trump', 1),\n",
              " ('three', 1),\n",
              " ('the World Health Organization', 1),\n",
              " ('Mike Ryan', 1),\n",
              " ('April', 1),\n",
              " ('under 3,000 and 40,000 -', 1),\n",
              " ('Ernesto Araújo', 1),\n",
              " ('Independence Day', 1),\n",
              " ('Brasilia', 1),\n",
              " ('4 July', 1),\n",
              " ('Folha de São Paulo', 1),\n",
              " ('nearly 1.7 million', 1),\n",
              " ('Will Jair Bolsonaro', 1),\n",
              " ('Latin America', 1),\n",
              " ('Amazonas', 1),\n",
              " ('Rio de Janeiro', 1),\n",
              " ('one million', 1),\n",
              " ('20 June', 1),\n",
              " ('1.5 million', 1),\n",
              " ('the past week', 1),\n",
              " ('One', 1),\n",
              " ('AstraZeneca and Sinovac', 1),\n",
              " ('thousands', 1),\n",
              " ('Brazilian', 1),\n",
              " ('2025', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "items = [x.text for x in parsed_article.ents]\n",
        "Counter(items).most_common()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEV2BJCTpdl7"
      },
      "source": [
        "Note that some of the phrases refer to the same entity, e.g. 'Mr Bolsonaro' and just 'Bolsonaro'.\n",
        "- Entity Linking and Reference Resolution are the NLP problems that deal with resolving the different references to the same entity in the text.\n",
        "\n",
        "If we were only interested in what was being said about Bolsonaro,\n",
        "- we could select only sentences refering to him:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNXjt46Jpdl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "9b2b9f7c-e8d7-4d38-9bd1-94a2891c4297"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " tests positive<br><br>\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tested positive for coronavirus.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has repeatedly played down risks of what he has called the &quot;little flu&quot;, saying he would not be seriously affected. </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that he had started experiencing symptoms on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is in a higher-risk group because of \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    his age, 65\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Contact tracing and tests will be carried out for the people Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has met recently.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The executive director of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the World Health Organization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Dr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mike Ryan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", wished President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " &quot;a speedy and full recovery from this disease&quot;, adding: &quot;I think the message to us all is: we are vulnerable to this virus.</div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;<br>Back in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    April\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said that even if infected, he would &quot;not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold&quot;.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Despite this, President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">On \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sunday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Foreign Minister \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ernesto Araújo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " posted a photo on social media showing himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others attending an \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Independence Day\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " celebration at the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    US\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " embassy said that the ambassador had had lunch with Mr \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and others on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    4 July\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The ambassador had earlier tweeted a picture of himself with President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".<br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">For so long, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has tried to brush off this virus - the irony that he has now caught it has not been missed in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">His detractors - of which he has many - have weighed in, calling this karma - that \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " invited this to happen. <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">There was even a column in one of the biggest newspapers, \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Folha de São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", entitled &quot;Why I'm Cheering for Bolsonaro to Die&quot; - this is how divided, how toxic  the political picture is here in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " as the pandemic takes hold. <br></div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">But the fact is, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " joins the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 1.7 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brazilians\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " who've contracted Covid-19. </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Will Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " get away with mild symptoms and carry on downplaying it? </div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sentences_containing_Bolsonaro = [x for x in parsed_article.sents if 'Bolsonaro' in x.text]\n",
        "displacy.render(sentences_containing_Bolsonaro,jupyter=True,style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkJvASO9pdl7"
      },
      "source": [
        "## Named Entity Extraction in Italian\n",
        "\n",
        "But wait, SpaCy can speak Italian too!\n",
        "- Let's make use of the pretrained italian model that we downloaded earlier: https://spacy.io/models/it\n",
        "- to recognise entities in an article from 'Il Corriere'\n",
        "\n",
        "First download the article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCTkJTsopdl7"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.ansa.it/sito/notizie/mondo/2020/07/07/bolsonaro-ha-i-sintomi-del-coronavirus_40d26967-e377-4455-9b42-83c2756cf5f1.html'\n",
        "html_doc = requests.get(url).text\n",
        "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrnqQcMOpdl7"
      },
      "source": [
        "Now let's extract the title and paragraph text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIyIysghpdl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc81485-eab3-40ef-b003-ccab2decd39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bolsonaro positivo al test del coronavirus - Mondo - ANSA\n",
            "\n",
            "Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento \"Consentless\" a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad ANSA.it.\n",
            "Ti invitiamo a leggere le Condizioni  Generali di Servizio, la Cookie Policy e l'Informativa Privacy. \n",
            "Puoi leggere tutti i titoli di ANSA.it e 10  contenuti ogni 30 giornia €16,99/anno\n",
            "Per accedere senza limiti a tutti i contenuti di ANSA.it\n",
            "Scegli il piano di  abbonamento più adatto alle tue esigenze.\n",
            "Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di ANSA.it e 10 contenuti ogni 30 giorni (servizio base):\n",
            "Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla Cookie Policy e all'Informativa Privacy. \n",
            "Per maggiori informazioni sui servizi di ANSA.it, puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a register@ansa.it o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    Il presidente brasiliano, Jair Bolsonaro, è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a Tv Brasil dal Palacio da Alvorada, sua residenza ufficiale a Brasilia.    Ieri Bolsonaro aveva detto di sentirsi \"molto meglio, anche la febbre è scesa\". Bolsonaro - che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, Donald Trump, anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo Paese.    In vetta ai 'trending topic' su Twitter in Brasile c'è infatti l'hashtag \"forca covid\" (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di Boris Johnson, pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di Bolsonaro, il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di Stato verdeoro.    Prima di sottoporsi al test, Bolsonaro ha effettuato anche un esame dei polmoni. \"Vengo dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il Covid, ma va tutto bene\", aveva spiegato lunedì sera il presidente della Repubblica a un gruppo di simpatizzanti che lo attendevano davanti al Palacio da Alvorada, la sua residenza ufficiale a Brasilia.   Bolsonaro si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli Stati Uniti, al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.\n",
            "22:39\n",
            "19:14\n",
            "12:06\n",
            "12:04\n",
            "12:01\n",
            "11:02\n",
            "10:49\n",
            "01:58\n"
          ]
        }
      ],
      "source": [
        "title = parsed_doc.find('title').text\n",
        "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
        "\n",
        "# Combine the title and paragraphs into a single text:\n",
        "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
        "print(article_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eluDQCqxpdl7"
      },
      "source": [
        "Now we'll parse the text of the article with an Italian NLP engine to extract Named Entities.\n",
        "- First load the italian model 'it_core_news_sm' that we downloaded earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0IIHlVpdl7"
      },
      "outputs": [],
      "source": [
        "import it_core_news_sm\n",
        "nlp_it = it_core_news_sm.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcWwDGlypdl8"
      },
      "source": [
        "Parse article and extract the entities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X-Kuw6lpdl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1b95035-0e07-4146-94ab-61eb751968dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " positivo al test del coronavirus - Mondo - \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "<br><br>Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento &quot;\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Consentless\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "&quot; a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ".<br>\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ti\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " invitiamo a leggere le \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Condizioni  Generali\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Servizio\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", la \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cookie Policy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " e l'\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Informativa Privacy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". <br>Puoi leggere tutti i titoli di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " e 10  contenuti ogni 30 giornia €16,99/anno<br>Per accedere senza limiti a tutti i contenuti di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "Scegli\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " il piano di  abbonamento più adatto alle tue esigenze.<br>Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " e 10 contenuti ogni 30 giorni (servizio base):<br>Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cookie Policy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " e all'\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Informativa Privacy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". <br>Per maggiori informazioni sui servizi di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ANSA.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    register@ansa.it\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.<br><br><br><br><br><br><br>    Il presidente brasiliano, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jair Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tv Brasil dal Palacio da Alvorada\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", sua residenza ufficiale a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".    \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ieri Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " aveva detto di sentirsi &quot;molto meglio, anche la febbre è scesa&quot;. \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro -\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donald Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paese\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".    In vetta ai 'trending topic' su \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Twitter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasile\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " c'è infatti l'\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hashtag\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " &quot;forca covid&quot; (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Boris Johnson\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stato\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " verdeoro.    Prima di sottoporsi al test, \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ha effettuato anche un esame dei polmoni. &quot;\n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Vengo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Covid\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", ma va tutto bene&quot;, aveva spiegato lunedì sera il presidente della \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Repubblica\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " a un gruppo di simpatizzanti che lo attendevano davanti al \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Palacio da Alvorada\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", la sua residenza ufficiale a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasilia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".   \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bolsonaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Stati Uniti\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.<br>22:39<br>19:14<br>12:06<br>12:04<br>12:01<br>11:02<br>10:49<br>01:58</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "parsed_article = nlp_it(article_text)\n",
        "displacy.render(parsed_article, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08h69wcxpdl8"
      },
      "source": [
        "That looks not great.\n",
        "- Here are the entities found in the news article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKefi_fspdl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35de4943-60f5-4259-d67b-8fb155d317f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ANSA',\n",
              " 'ANSA.it',\n",
              " 'ANSA.it\\nScegli',\n",
              " 'Bolsonaro',\n",
              " 'Bolsonaro -',\n",
              " 'Boris Johnson',\n",
              " 'Brasile',\n",
              " 'Brasilia',\n",
              " 'Condizioni  Generali',\n",
              " 'Consentless',\n",
              " 'Cookie Policy',\n",
              " 'Covid',\n",
              " 'Donald Trump',\n",
              " 'Ieri Bolsonaro',\n",
              " 'Informativa Privacy',\n",
              " 'Jair Bolsonaro',\n",
              " 'Paese',\n",
              " 'Palacio da Alvorada',\n",
              " 'Repubblica',\n",
              " 'Servizio',\n",
              " 'Stati Uniti',\n",
              " 'Stato',\n",
              " 'Ti',\n",
              " 'Tv Brasil dal Palacio da Alvorada',\n",
              " 'Twitter',\n",
              " 'Vengo',\n",
              " 'hashtag',\n",
              " 'register@ansa.it']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "sorted(set(x.text for x in parsed_article.ents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMb8j2-2XkPc"
      },
      "source": [
        "## Text Classification with a Recurrent Neural Network (using TensorFlow)\n",
        "\n",
        "In this last section of the notebook I will run through a quick example of using a Bidirectional LSTM (Long Short-term Memory) network for text classification.\n",
        "- RNNs extend embedding-based classification of text by taking word-order into account. They were, until relatively recently, the state-of-the-art when it came to training text classifiers.\n",
        "- Tensorflow is sophisticated toolkit for building Deep Neural Network models. We will use it to build the model. The tutorial follows mostly this Tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
        "    - Tensorflow is to deep learning learning what Java is to programming (joking...?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysjOGZrnXkPc"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdiXno9jXkPc"
      },
      "source": [
        "First let's load the Twitter dataset we used in the second session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX-qsv-IXkPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b157b9e0-8e80-4468-a1f1-893cc88f47f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "from nltk.corpus import twitter_samples\n",
        "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKS2HdEXkPc"
      },
      "source": [
        "Remove emoticons from the positive and negative examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQqqGPlYXkPc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
        "positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n",
        "negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMo6g9mcXkPc"
      },
      "source": [
        "And create the examples and labels as we did before. This time we will use numeric labels (0,1) instead of text labels ('negative','positive'), since the deep learning library we will use requires numeric class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVAlgu-IXkPc"
      },
      "outputs": [],
      "source": [
        "tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n",
        "tweets_y = [1]*len(positive_tweets) + [0]*len(negative_tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMJO18SXkPc"
      },
      "source": [
        "And again, split the data into training, validation and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2eXMPFuXkPc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFRtKN0gXkPc"
      },
      "source": [
        "Now that we have the training and validation data prepared, we can import the Tensorflow library, and use it to load the training and validaton datasets into the tensorflow format. Note that:\n",
        "- Tensorflow comes installed on Google Colab.\n",
        "- If you run this notebook on your own machine you will need to first install tensorflow using '!pip install'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow 2 and tf.keras\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBNoC2SQ6EKG",
        "outputId": "6aded9e9-a7a0-4cf6-ddce-4f7ac5a74f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gykDCG4YXkPc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_tf = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_tf = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeZgqPQYXkPc"
      },
      "source": [
        "Training will run on *batches* of the data at a time, so we need to create them.\n",
        "- We first use the shuffle command to randomise the order of the training data. (The buffer-size limits the number of instances loaded into memory when shuffling and is only for efficiency -- you could remove it.)\n",
        "- We then create the batches. Each batch will contain 64 examples.\n",
        "- The validation data needs to have the same format as the training data, so we batch it too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3k_AJMVXkPc"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_tf.shuffle(buffer_size=10000).batch(batch_size=64).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_tf.batch(batch_size=64).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCIJun8hXkPc"
      },
      "source": [
        "Let's have a look at the first batch in the training data. It consists of:\n",
        "- an array of strings (tweets)\n",
        "- an array of binary values (class labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sqXOO8JXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02fc44e5-075e-43bb-f95d-8520f9b393ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(64,), dtype=string, numpy=\n",
            "array([b'i drew @JustinNFJK :))\\n#WIP #SWS #crush @SWStheband http://t.co/DGiqiOR63a',\n",
            "       b'@Jurisprude1 Then about six months ago, bottom jaw, second tooth from the back broke a quarter... on all things, chewing gum! ',\n",
            "       b'Raining the whole day in Mumbai. Don\\xe2\\x80\\x99t feel like working at all. ',\n",
            "       b'@Benzyyyyy with you talaga the best.  \\xf0\\x9f\\x98\\x82',\n",
            "       b\"Happy b'day @HathwalaThakur \",\n",
            "       b'@dumplinghoya :(( but I want to get at least a little bit older so I can do stuff XD',\n",
            "       b'U cant change how people feel about u so dnt try , just live ur life and  be happy ',\n",
            "       b\"At least I think Marrish is happening, not as my others otp's \",\n",
            "       b\"@KEEMSTARx And people ask why I don't leave my house, the world is scary and fucked. \\nShootings and explosions everywhere \",\n",
            "       b'In #Fallout4 we get to see the Glowing Sea. Again. \\n\\nTechnically did in Fallout 3. I just played again to see  http://t.co/zRP17qI0qT',\n",
            "       b\"i used to have such nice hair :(( look at it it's all shiny and long and wavy im emo http://t.co/qX7XO8x5Zq\",\n",
            "       b'i miss them already ',\n",
            "       b'@PagePlannerLive Thank you  This is getting retweeted x',\n",
            "       b'but look forward to joining the conversation! \\n@ArmonRaE @lordcropes no movie has but books',\n",
            "       b'@DeEstrellados hello, any info about possible interest of Jonathas ?? Hes close to Betis ',\n",
            "       b'@PKMN_Assassin GARRET!!! \\xe2\\x9d\\xa4 ',\n",
            "       b'@davidwarner31 Awwww! Ivy,I love her so much,more than you I wanna meet her! ^-^ Sho cute and sweet.  #Angel ',\n",
            "       b'@RafaelAllmark why unfollow??? Please follow me again!!!  colombia loves you!!',\n",
            "       b'@HeelSimba  well let me know on the day if after work you feel like socialising and I will make time for you!',\n",
            "       b'@Real_Liam_Payne please follow me liam ',\n",
            "       b'@ICTDSeSafety Its on my to do list, just about to board so see you in a couple of weeks ',\n",
            "       b'Would be cool to fall asleep on the phone with oomf ',\n",
            "       b'@HelenAnn_Davies Thanks Helen! Keep in touch and if you ever want to do any filming with the blood service you know where I am! ',\n",
            "       b'@JonicaYacap  follow @jnlazts &amp; http://t.co/RCvcYYO0Iq follow u back ',\n",
            "       b'@lostboxuk Very sad! ', b'Evening :(((',\n",
            "       b'@traveldudes Try burek (with meat) or gibanica (cheese pie) for breakfast ',\n",
            "       b'@cxshtonhemiford Follow me again ? i forgot to followback and you unfollowed me :(((',\n",
            "       b'@hclcampbell Amazing! Glad to hear we could make your Friday morning a little better  ^KS',\n",
            "       b'@stokebrisbane Hi! Saw who u follow and thought u might like \"Dark\" https://t.co/CFl0s5hwWw .Plz let us know what u think ',\n",
            "       b'@PB_Furniture @whittakerdesig1 @smart_bn @Klick_Business @HartleysRooms @REDlineCC @RedBizUK @earlybiz Woooo! Happy Friday friends  #ff',\n",
            "       b'@marshyymiullow you have a weird DP, you know? ',\n",
            "       b'@Hanan_nisaS mind to follow back? ',\n",
            "       b'I miss being a kid  http://t.co/724BGj38Hq',\n",
            "       b'@calv_18 came up on my time hop  #bestweekend',\n",
            "       b'Men are like power tools. They make a lot of noise but its hard to get them to work. ',\n",
            "       b'@unwoman EVERYONE adored you. Talking about it long after you left. New fans. I knew that would be the case. ',\n",
            "       b\"please beliebers stop voting on twitter! it doesn't count \\nu have to vote here http://t.co/PkD4q2PVxV n refresh it http://t.co/Lh5sNTHmIV\",\n",
            "       b'he he he ',\n",
            "       b'Finished our development testing out in Spain , next up are the official tests. Who is excited for season 2 ?? http://t.co/FxQ4P0bMH7',\n",
            "       b'Thug ',\n",
            "       b'How unlucky would it be if I was dying and passed away just before ed came on stage #',\n",
            "       b'@thingforasians hi my hot girl did I say how very hot and horny you are darling xx  \\xe2\\x99\\xa5',\n",
            "       b'I do, bby. And i might take one now.   https://t.co/hfo3KcFu0n',\n",
            "       b'Here &gt;&gt; Free $5 Voucher for my twitter friends to use on Fiverr  https://t.co/ozKEhcY9ML http://t.co/nfDSHggVV7',\n",
            "       b'Awww i thought it was today  https://t.co/JK8xRlW6IF',\n",
            "       b\"@azzzzyb :((( I'm helping you :((((((((\",\n",
            "       b'\\xe2\\x80\\x9c@JaDine_Addicts: Goodafternoon JaDines, THIZ IZ IT EMEGED I KENNAT :((((( -G\\n\\n#OTWOLGrandTrailer\\xe2\\x80\\x9d',\n",
            "       b\"@ranaPTX_ BUT WHO WILL LEAD US WHEN YOU'RE GONE :((\",\n",
            "       b'I need to find a boy that loves fireball just as much as I do ',\n",
            "       b\"@itradeland that's one of mine. Button pusher. Out soon \",\n",
            "       b'#JUMMA_MUBARIK &lt &lt &lt \\nto aLL #FrNds   \\n          #StaY_BlesseD    \\xe2\\x80\\x94 feeling blessed',\n",
            "       b'Fk!!!!! I have no freaking words to describe this.... Eric Prydz How? like how?  This is out of the world!! http://t.co/W5uDTzdhAi',\n",
            "       b'I THINK THIS IS FROM THEIR FIFTH ALBUM IM  OKAY  FUCK  https://t.co/qzT5Zsm8RE',\n",
            "       b'Rly sad that I had to rush off when that was the last time I would see everyone ',\n",
            "       b\"@Clareyh Yeah, it's a classy look . I've seen people attached to all sorts of 'life saving' equipment, some in beds,having their fix :-0)\",\n",
            "       b'11:11 a boyfriend ', b'I LIKE PUNS  http://t.co/jPtWXGc4tg',\n",
            "       b\"i didn't realize it was 3 am i was watching concert videos and pcd is extremely hard rn \",\n",
            "       b\"Too many people asking when I'm back in LA \",\n",
            "       b'This woman just gave me the warmest greeting, w a chin tickle even, but I think she has the wrong girl ',\n",
            "       b\"i'm such a terrible daughter \",\n",
            "       b\"@MooseAllain @MeatBingo that is the just most wonderful thing, it's made me feel all fluffy inside. Great pirouette, Moose \",\n",
            "       b\"Of course I always miss @selenagomez's Tweeting sprees \"],\n",
            "      dtype=object)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
            "array([1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
            "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
            "      dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataset.take(1):\n",
        "  print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTwmMzIoXkPd"
      },
      "source": [
        "Now that we have the text data in the format required, we can vectorize it. We will need to make use a specific text vectorization module from tensorflow to do this.\n",
        "- We first limit the vocabulary of the vectorizer to 5000,\n",
        "- then extract only the text portion of the training dataset,\n",
        "- and finally fit the vectorizer to the text using the 'adapt' method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6BrcfEoXkPd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "vectorizer = TextVectorization(max_tokens=5000)\n",
        "train_text = train_dataset.map(lambda text, label: text)\n",
        "vectorizer.adapt(train_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lVOC3srXkPd"
      },
      "source": [
        "Let's print out the first tokens form the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDErP-eLXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dcc3d5-0483-4032-d3a9-5cd6459f471c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('you'),\n",
              " np.str_('the'),\n",
              " np.str_('a'),\n",
              " np.str_('and'),\n",
              " np.str_('my'),\n",
              " np.str_('for'),\n",
              " np.str_('me'),\n",
              " np.str_('it'),\n",
              " np.str_('is'),\n",
              " np.str_('in'),\n",
              " np.str_('so'),\n",
              " np.str_('of'),\n",
              " np.str_('have'),\n",
              " np.str_('im'),\n",
              " np.str_('on'),\n",
              " np.str_('that'),\n",
              " np.str_('this'),\n",
              " np.str_('but'),\n",
              " np.str_('be'),\n",
              " np.str_('its'),\n",
              " np.str_('your'),\n",
              " np.str_('thanks'),\n",
              " np.str_('like'),\n",
              " np.str_('just'),\n",
              " np.str_('follow'),\n",
              " np.str_('no'),\n",
              " np.str_('not'),\n",
              " np.str_('u'),\n",
              " np.str_('love'),\n",
              " np.str_('with'),\n",
              " np.str_('all'),\n",
              " np.str_('please'),\n",
              " np.str_('was'),\n",
              " np.str_('we'),\n",
              " np.str_('at'),\n",
              " np.str_('can'),\n",
              " np.str_('too'),\n",
              " np.str_('are'),\n",
              " np.str_('dont'),\n",
              " np.str_('get'),\n",
              " np.str_('do'),\n",
              " np.str_('good'),\n",
              " np.str_('day'),\n",
              " np.str_('up'),\n",
              " np.str_('cant'),\n",
              " np.str_('now'),\n",
              " np.str_('want'),\n",
              " np.str_('if'),\n",
              " np.str_('back'),\n",
              " np.str_('see'),\n",
              " np.str_('know'),\n",
              " np.str_('will'),\n",
              " np.str_('one'),\n",
              " np.str_('miss'),\n",
              " np.str_('thank'),\n",
              " np.str_('amp'),\n",
              " np.str_('what'),\n",
              " np.str_('time'),\n",
              " np.str_('out'),\n",
              " np.str_('happy'),\n",
              " np.str_('when'),\n",
              " np.str_('much'),\n",
              " np.str_('today'),\n",
              " np.str_('hi'),\n",
              " np.str_('about'),\n",
              " np.str_('go'),\n",
              " np.str_('why'),\n",
              " np.str_('from'),\n",
              " np.str_('really'),\n",
              " np.str_('new'),\n",
              " np.str_('great'),\n",
              " np.str_('our'),\n",
              " np.str_('they'),\n",
              " np.str_('still'),\n",
              " np.str_('more'),\n",
              " np.str_('he'),\n",
              " np.str_('us'),\n",
              " np.str_('how'),\n",
              " np.str_('hope'),\n",
              " np.str_('sorry'),\n",
              " np.str_('here'),\n",
              " np.str_('going'),\n",
              " np.str_('am'),\n",
              " np.str_('been'),\n",
              " np.str_('there'),\n",
              " np.str_('work'),\n",
              " np.str_('got'),\n",
              " np.str_('as'),\n",
              " np.str_('need'),\n",
              " np.str_('would'),\n",
              " np.str_('an'),\n",
              " np.str_('again'),\n",
              " np.str_('youre'),\n",
              " np.str_('well'),\n",
              " np.str_('ill'),\n",
              " np.str_('some')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "vocab = vectorizer.get_vocabulary()\n",
        "vocab[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2AnCbfIXkPd"
      },
      "source": [
        "Note that the first two tokens in the vocabulary are the empty token '', and the unknown token '[UNK]'. The latter is used to mask out-of-vocabulary tokens in the text\n",
        "\n",
        "We can now use the vectorizer to encode a tweet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reL7OIXpXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6aeb77b-57b1-4f16-d3f6-2011d6ab0215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet:      This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?\n",
            "Encoded:    [ 20  12   8 182 240  11   1  56   1   1 166   1   9   1  20 240]\n",
            "Recovered:  this is my first tweet it [UNK] one [UNK] [UNK] any [UNK] for [UNK] this tweet\n"
          ]
        }
      ],
      "source": [
        "text = 'This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?'\n",
        "encoding = vectorizer([text]).numpy()[0]\n",
        "print('Tweet:     ', text)\n",
        "print('Encoded:   ', encoding)\n",
        "print('Recovered: ',' '.join([vocab[i] for i in encoding]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0wCv-cPXkPd"
      },
      "source": [
        "Note that the vectorizer is not turning the text into a single vector, but is simply replacing the vocabulary words by their indices. If a word is not present in the dictionary it is replaced by the unknown token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAeaJ6WvXkPd"
      },
      "source": [
        "Let's have a look at some actual examples from the dataset, printing out the first 6 tweets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aghpfMAXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3577dc3c-cca6-41bb-9728-2e99348cc649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet:      i drew @JustinNFJK :))\n",
            "#WIP #SWS #crush @SWStheband http://t.co/DGiqiOR63a\n",
            "Encoded:    [   2 2029    1 2252    1 1552    1    1]\n",
            "Recovered:  i drew [UNK] wip [UNK] crush [UNK] [UNK]\n",
            "\n",
            "Tweet:      @Jurisprude1 Then about six months ago, bottom jaw, second tooth from the back broke a quarter... on all things, chewing gum! \n",
            "Encoded:    [   1  135   68 2466  911  500 2113    1  599 1349   71    5   52  766\n",
            "    6    1   18   34  241 3404    1]\n",
            "Recovered:  [UNK] then about six months ago bottom [UNK] second tooth from the back broke a [UNK] on all things chewing [UNK]\n",
            "\n",
            "Tweet:      Raining the whole day in Mumbai. Don’t feel like working at all. \n",
            "Encoded:    [ 726    5  437   46   13 2774 1259  106   26  230   38   34]\n",
            "Recovered:  raining the whole day in mumbai don’t feel like working at all\n",
            "\n",
            "Tweet:      @Benzyyyyy with you talaga the best.  😂\n",
            "Encoded:    [  1  33   4   1   5 177 776]\n",
            "Recovered:  [UNK] with you [UNK] the best 😂\n",
            "\n",
            "Tweet:      Happy b'day @HathwalaThakur \n",
            "Encoded:    [ 63 586   1]\n",
            "Recovered:  happy bday [UNK]\n",
            "\n",
            "Tweet:      @dumplinghoya :(( but I want to get at least a little bit older so I can do stuff XD\n",
            "Encoded:    [   1   21    2   50    3   43   38  493    6  251  456 1809   14    2\n",
            "   39   44  624  866]\n",
            "Recovered:  [UNK] but i want to get at least a little bit older so i can do stuff xd\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for text in batch[0][:6].numpy():\n",
        "    encoding = vectorizer([text]).numpy()[0]\n",
        "    print('Tweet:     ', text.decode(\"utf-8\"))\n",
        "    print('Encoded:   ', encoding)\n",
        "    print('Recovered: ',' '.join([vocab[i] for i in encoding]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeDyajurXkPd"
      },
      "source": [
        "### Defining and Training the RNN model\n",
        "\n",
        "Now we can define the model, which contains four layers:\n",
        "- an input embedding layer which produces word embeddings of size 64\n",
        "- a bidirectional LSTM layer\n",
        "- 2 dense (aka fully connected) layers that maps the 2 embedding vectors (of size 64) produced by the bidirectional LSTM down to a single neuron   \n",
        "\n",
        "This constitutes a relatively standard basic RNN architecture. (The details of why these specific components are chosen is beyond the scope of this tutorial.)  \n",
        "\n",
        "Once the model has been defined it is compiled in the following step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7Db-xGTXkPd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
        "    vectorizer,\n",
        "    tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the output of a Bidirectional Layer is a concatenation of the forward and backward outputs. So the output of the Bidirectional layer is actually a tensor of size 128, which we project down first to a 64 size vector and than to a single neurons.\n",
        "- We can see this behaviour using the built in summary() method\n",
        "- We can also get an understanding of the number of parameters in the model!"
      ],
      "metadata": {
        "id": "F1rDwYISeVkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "5sTJuxM9eOXF",
        "outputId": "5ad47a28-e5b9-44c1-81e4-97ba63a2cf1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m394,369\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,369</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,369\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,369</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the parameters are used to define the embedding, then the LSTMs."
      ],
      "metadata": {
        "id": "0HfV0Z4Ff4z8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDcdvj3fXkPd"
      },
      "source": [
        "Fit the model by running it for 10 epochs (iterations over the training data).\n",
        "- Note that we provide it with both the training dataset and the validation dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNij_XUrXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba82206-d4c5-4d54-a029-98687fcf6886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.5062 - loss: 0.6921 - val_accuracy: 0.4898 - val_loss: 0.6843\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.5076 - loss: 0.6756 - val_accuracy: 0.6313 - val_loss: 0.6221\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.6682 - loss: 0.5810 - val_accuracy: 0.6898 - val_loss: 0.5481\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7553 - loss: 0.4873 - val_accuracy: 0.7367 - val_loss: 0.5368\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 155ms/step - accuracy: 0.8158 - loss: 0.4031 - val_accuracy: 0.7367 - val_loss: 0.5255\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 70ms/step - accuracy: 0.8424 - loss: 0.3581 - val_accuracy: 0.7445 - val_loss: 0.5594\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8657 - loss: 0.3089 - val_accuracy: 0.7430 - val_loss: 0.5954\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.8873 - loss: 0.2734 - val_accuracy: 0.7383 - val_loss: 0.6451\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.9032 - loss: 0.2500 - val_accuracy: 0.7367 - val_loss: 0.6649\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9072 - loss: 0.2255 - val_accuracy: 0.7320 - val_loss: 0.7296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4894853a90>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model.fit(train_dataset, epochs=10, validation_data=valid_dataset, validation_steps=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chkFHzAjXkPd"
      },
      "source": [
        "Once we've trained the model we can check the final accuracy on the validation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VGjzmPPXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d097a32-2082-4422-e8ad-ad022198212b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7417 - loss: 0.7179\n",
            "Validation Loss: 0.7210513949394226\n",
            "Validation Accuracy:  0.7406250238418579\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_acc = model.evaluate(valid_dataset)\n",
        "\n",
        "print('Validation Loss: {}'.format(valid_loss))\n",
        "print('Validation Accuracy: ',valid_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUFlKyZwXkPd"
      },
      "source": [
        "We can have a look at the predictions from the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n44pazsNXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f3131c-39bf-4973-fd00-eb950d3272f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
            "tweet:  I can't believe how much fun I'm having learning to train a text classifier with a bidirectional LSTM!\n",
            "encoded as:  i cant believe how much fun im having [UNK] to train a text [UNK] with a [UNK] [UNK]\n",
            "predicted value:  4.076703\n",
            "predicted label:  positive\n",
            "\n",
            "tweet:  I am really confused. I want my mommy.\n",
            "encoded as:  i am really confused i want my mommy\n",
            "predicted value:  -4.2528815\n",
            "predicted label:  negative\n",
            "\n",
            "tweet:  The internet connection has been pretty annoying today!\n",
            "encoded as:  the internet connection has been pretty annoying today\n",
            "predicted value:  -3.8154862\n",
            "predicted label:  negative\n",
            "\n",
            "tweet:  They just played my favourite song on the radio.\n",
            "encoded as:  they just played my favourite song on the radio\n",
            "predicted value:  0.26384586\n",
            "predicted label:  positive\n",
            "\n",
            "tweet:  I don't like going to the dentist.\n",
            "encoded as:  i dont like going to the [UNK]\n",
            "predicted value:  -0.037563413\n",
            "predicted label:  negative\n",
            "\n",
            "tweet:  I am so happy today!\n",
            "encoded as:  i am so happy today\n",
            "predicted value:  1.8198695\n",
            "predicted label:  positive\n",
            "\n",
            "tweet:  I am so unhappy today!\n",
            "encoded as:  i am so unhappy today\n",
            "predicted value:  -1.0630054\n",
            "predicted label:  negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tweets = []\n",
        "tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier with a bidirectional LSTM!')\n",
        "tweets.append('I am really confused. I want my mommy.')\n",
        "tweets.append('The internet connection has been pretty annoying today!')\n",
        "tweets.append('They just played my favourite song on the radio.')\n",
        "tweets.append(\"I don't like going to the dentist.\")\n",
        "tweets.append('I am so happy today!')\n",
        "tweets.append('I am so unhappy today!')\n",
        "\n",
        "predictions = model.predict(tf.convert_to_tensor(tweets))\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  print('tweet: ',tweets[i])\n",
        "  encoding = vectorizer([tweets[i]]).numpy()[0]\n",
        "  print('encoded as: ',' '.join([vocab[j] for j in encoding]))\n",
        "  print('predicted value: ', predictions[i][0])\n",
        "  print('predicted label: ', 'negative' if (predictions[i]<0) else 'positive')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV-2gZZtXkPd"
      },
      "source": [
        "And calculate the usual evaluation metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-dBXIPMEXkPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "78d758cc-ee95-4ac1-a054-1bf57d781bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "accuracy: 0.7425\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f48941e6b50>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pred_y = [0 if (pred < 0) else 1 for pred in model.predict(tf.convert_to_tensor(valid_x))]\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy: '+ str(accuracy_score(pred_y, valid_y)))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cmd = ConfusionMatrixDisplay(confusion_matrix(valid_y, pred_y,normalize='true'), display_labels=['negative', 'positive'])\n",
        "cmd.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-BKhc-eXkPd"
      },
      "source": [
        "Finally, let's print out the model summary to get an understanding of the number of parameters in the model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMS2GYrKXkPO"
      },
      "source": [
        "## Sequence labelling with Recurrent Neural Network (using PyTorch)\n",
        "\n",
        "In this section of the notebook I will run through an example of using LSTM (Long Short-term Memory) network for text sequence labelling.\n",
        "We can train our own model for POS-tagging or NER.\n",
        "Moreover, we can use pre-trained embedding models to encode the input text.\n",
        "\n",
        "- We are going to use PyTorch (https://pytorch.org) to build and train our model. Pytorch is a state-of-the-art framework for deep leaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6xs4SfcXkPP"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "As usual we start from data preparation.\n",
        "We can use the [CoNLL 2003](https://www.clips.uantwerpen.be/conll2003/ner/) corpus, which provides corpora for POS-tagging, Chunking and NER in English and German.\n",
        "Today we are going to focus on NER in English.\n",
        "\n",
        "You can find a copy the English split in the `docs/` directory.\n",
        "Usually the corpus should require preprocessing the data, here I am providing you with a version from Kaggle where documents have already been tagged (source: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion?resource=download)\n",
        "\n",
        "Let's start by loading the three files (train/validation/test) in memory and reading all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BONoKuGNXkPP",
        "outputId": "bc40eb35-3dc8-4e4e-b83c-2327f218ef30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP B-NP B-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP B-NP B-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT B-NP O\n",
            "European NNP I-NP B-ORG\n",
            "Commission NNP I-NP I-ORG\n",
            "said VBD B-VP O\n",
            "on IN B-PP O\n",
            "Thursday NNP B-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD B-VP O\n",
            "with IN B-PP O\n",
            "German JJ B-NP B-MISC\n",
            "advice NN I-NP O\n",
            "to TO B-PP O\n",
            "consumers NNS B-NP\n"
          ]
        }
      ],
      "source": [
        "raw_data = dict()\n",
        "\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    with open(f'docs/CoNLL - 2003/{split}.txt') as f:\n",
        "        raw_data[split] = f.read().strip()\n",
        "\n",
        "print(raw_data['train'][:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw6GFYkCXkPP"
      },
      "source": [
        "Now we can parse the data.\n",
        "Documents inside each split are separated by the sequence `-DOCSTART- -X- -X- O`.\n",
        "Sentences inside each document are separated by the sequence`\\n\\n` (two new-line characters).\n",
        "Each line inside a sentence represnets a token followed by the POS tag, the CHUNK tag and the NER tag, all separated by spaces.\n",
        "\n",
        "Here NER tags are written using a system called BIO-tagging.\n",
        "The 'B' stands for \"begin\" and introduces (starts) a new named entity, the tags are written as \"B-PER\" to indicate a person or \"B-LOC\" to indicate a location and so on.\n",
        "The 'I' stands for \"inside\" and continues a started named entity, the tags are written as \"I-PER\" to indicate a person or \"I-LOC\" to indicate a location and so on.\n",
        "The 'O' stands for outside, it means that the token is outside any named entity.\n",
        "There are other tagging systems.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xagcI6jWXkPP"
      },
      "outputs": [],
      "source": [
        "keys = ['text', 'pos_tag', 'chunk_tag', 'ner_tag']\n",
        "\n",
        "data = dict()\n",
        "\n",
        "for split in raw_data:\n",
        "    data[split] = list()\n",
        "    for doc in raw_data[split].split('-DOCSTART- -X- -X- O')[1:]:\n",
        "        for sentence in doc.strip().split('\\n\\n'):\n",
        "            data[split].append(list())\n",
        "            for elem in sentence.split('\\n'):\n",
        "                data[split][-1].append(dict(zip(keys, elem.split())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXZPjL6RXkPP",
        "outputId": "b8d460db-ffa7-4958-83c4-de322005adc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
              " {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              " {'text': 'German', 'pos_tag': 'JJ', 'chunk_tag': 'B-NP', 'ner_tag': 'B-MISC'},\n",
              " {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              " {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              " {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
              " {'text': 'British',\n",
              "  'pos_tag': 'JJ',\n",
              "  'chunk_tag': 'B-NP',\n",
              "  'ner_tag': 'B-MISC'},\n",
              " {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              " {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "data['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGQgUUNIXkPQ"
      },
      "source": [
        "Now all the labels are properly organised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtmKiY5eXkPQ"
      },
      "source": [
        "At this point we need a system to encode and decode the labels into categorical entities.\n",
        "We can use the label encoder from Scikit-Learn for that (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjLyqAhgXkPQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pos_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
        "chunk_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
        "ner_le = LabelEncoder().fit([token['ner_tag'] for split in data.values() for sentence in split for token in sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVFW52o8XkPQ"
      },
      "source": [
        "Now we have a module mapping from tags to IDs and vice-versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93KtbCVBXkPQ",
        "outputId": "ca94906d-0405-47c4-aa10-36b38ea814ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "ner_tag = ['I-PER']\n",
        "ner_tag = ['I-LOC']\n",
        "ner_tag = ['B-PER']\n",
        "# ner_tag = ['O']\n",
        "\n",
        "ner_le.transform(ner_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFDxhaMnXkPQ",
        "outputId": "55de7c71-b945-4468-e17e-216d9b998952"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-LOC'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "ner_tag_id = [0]\n",
        "\n",
        "ner_le.inverse_transform(ner_tag_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOVxouSbXkPQ"
      },
      "source": [
        "How many NER tags do we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP7h6lsQXkPQ",
        "outputId": "3111952b-8a96-4c8e-dc7e-969d9309941b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "len(ner_le.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObAM_0yLXkPQ"
      },
      "source": [
        "Which are those tags?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cNrY9QmXkPQ",
        "outputId": "f9bccdfd-b12a-47e9-8a1f-3b2fbac57297"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
              "       'I-PER', 'O'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "ner_le.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuOZxaJVXkPQ"
      },
      "source": [
        "Finally we separate our train-validation-test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghCasG1MXkPQ"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = data.values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejkBWKyN5kpo",
        "outputId": "85b62e22-0326-4092-d2ab-12f7dd5adbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
              " {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              " {'text': 'German', 'pos_tag': 'JJ', 'chunk_tag': 'B-NP', 'ner_tag': 'B-MISC'},\n",
              " {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              " {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
              " {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
              " {'text': 'British',\n",
              "  'pos_tag': 'JJ',\n",
              "  'chunk_tag': 'B-NP',\n",
              "  'ner_tag': 'B-MISC'},\n",
              " {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
              " {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's build our simple vocabulary made up of all the words in our training set. We need a mapping of word->token to use to feed our network."
      ],
      "metadata": {
        "id": "6PmNu1Rl3Yy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab_and_tags(data):\n",
        "    word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}  # Il token di padding e il token delle parole out-of-vocabulary hanno indici riservati\n",
        "    tag2idx = {\"<PAD>\": 0}  # Deve essere lo stesso indice di padding degll'input!\n",
        "    for sent in data:\n",
        "        for token in sent:\n",
        "            word = token[\"text\"]\n",
        "            tag = token[\"ner_tag\"]\n",
        "            if word not in word2idx:\n",
        "                word2idx[word] = len(word2idx)\n",
        "            if tag not in tag2idx:\n",
        "                tag2idx[tag] = len(tag2idx)\n",
        "    return word2idx, tag2idx\n",
        "\n",
        "word2idx, tag2idx = build_vocab_and_tags(train_data)\n",
        "vocab_size = len(word2idx)\n",
        "num_tags = len(tag2idx)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"Number of NER tags: {num_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZOW6gjY9LKJ",
        "outputId": "c3b0f457-5f0a-41f2-cb10-7116fb0b409c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23625\n",
            "Number of NER tags: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can inspect our mapping:"
      ],
      "metadata": {
        "id": "DchV6p61-nOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxSkn0M--qfx",
        "outputId": "bf67731e-337c-4103-9703-ef034c7f1609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " '<UNK>': 1,\n",
              " 'EU': 2,\n",
              " 'rejects': 3,\n",
              " 'German': 4,\n",
              " 'call': 5,\n",
              " 'to': 6,\n",
              " 'boycott': 7,\n",
              " 'British': 8,\n",
              " 'lamb': 9,\n",
              " '.': 10,\n",
              " 'Peter': 11,\n",
              " 'Blackburn': 12,\n",
              " 'BRUSSELS': 13,\n",
              " '1996-08-22': 14,\n",
              " 'The': 15,\n",
              " 'European': 16,\n",
              " 'Commission': 17,\n",
              " 'said': 18,\n",
              " 'on': 19,\n",
              " 'Thursday': 20,\n",
              " 'it': 21,\n",
              " 'disagreed': 22,\n",
              " 'with': 23,\n",
              " 'advice': 24,\n",
              " 'consumers': 25,\n",
              " 'shun': 26,\n",
              " 'until': 27,\n",
              " 'scientists': 28,\n",
              " 'determine': 29,\n",
              " 'whether': 30,\n",
              " 'mad': 31,\n",
              " 'cow': 32,\n",
              " 'disease': 33,\n",
              " 'can': 34,\n",
              " 'be': 35,\n",
              " 'transmitted': 36,\n",
              " 'sheep': 37,\n",
              " 'Germany': 38,\n",
              " \"'s\": 39,\n",
              " 'representative': 40,\n",
              " 'the': 41,\n",
              " 'Union': 42,\n",
              " 'veterinary': 43,\n",
              " 'committee': 44,\n",
              " 'Werner': 45,\n",
              " 'Zwingmann': 46,\n",
              " 'Wednesday': 47,\n",
              " 'should': 48,\n",
              " 'buy': 49,\n",
              " 'sheepmeat': 50,\n",
              " 'from': 51,\n",
              " 'countries': 52,\n",
              " 'other': 53,\n",
              " 'than': 54,\n",
              " 'Britain': 55,\n",
              " 'scientific': 56,\n",
              " 'was': 57,\n",
              " 'clearer': 58,\n",
              " '\"': 59,\n",
              " 'We': 60,\n",
              " 'do': 61,\n",
              " \"n't\": 62,\n",
              " 'support': 63,\n",
              " 'any': 64,\n",
              " 'such': 65,\n",
              " 'recommendation': 66,\n",
              " 'because': 67,\n",
              " 'we': 68,\n",
              " 'see': 69,\n",
              " 'grounds': 70,\n",
              " 'for': 71,\n",
              " ',': 72,\n",
              " 'chief': 73,\n",
              " 'spokesman': 74,\n",
              " 'Nikolaus': 75,\n",
              " 'van': 76,\n",
              " 'der': 77,\n",
              " 'Pas': 78,\n",
              " 'told': 79,\n",
              " 'a': 80,\n",
              " 'news': 81,\n",
              " 'briefing': 82,\n",
              " 'He': 83,\n",
              " 'further': 84,\n",
              " 'study': 85,\n",
              " 'required': 86,\n",
              " 'and': 87,\n",
              " 'if': 88,\n",
              " 'found': 89,\n",
              " 'that': 90,\n",
              " 'action': 91,\n",
              " 'needed': 92,\n",
              " 'taken': 93,\n",
              " 'by': 94,\n",
              " 'proposal': 95,\n",
              " 'last': 96,\n",
              " 'month': 97,\n",
              " 'Farm': 98,\n",
              " 'Commissioner': 99,\n",
              " 'Franz': 100,\n",
              " 'Fischler': 101,\n",
              " 'ban': 102,\n",
              " 'brains': 103,\n",
              " 'spleens': 104,\n",
              " 'spinal': 105,\n",
              " 'cords': 106,\n",
              " 'human': 107,\n",
              " 'animal': 108,\n",
              " 'food': 109,\n",
              " 'chains': 110,\n",
              " 'highly': 111,\n",
              " 'specific': 112,\n",
              " 'precautionary': 113,\n",
              " 'move': 114,\n",
              " 'protect': 115,\n",
              " 'health': 116,\n",
              " 'proposed': 117,\n",
              " 'EU-wide': 118,\n",
              " 'measures': 119,\n",
              " 'after': 120,\n",
              " 'reports': 121,\n",
              " 'France': 122,\n",
              " 'under': 123,\n",
              " 'laboratory': 124,\n",
              " 'conditions': 125,\n",
              " 'could': 126,\n",
              " 'contract': 127,\n",
              " 'Bovine': 128,\n",
              " 'Spongiform': 129,\n",
              " 'Encephalopathy': 130,\n",
              " '(': 131,\n",
              " 'BSE': 132,\n",
              " ')': 133,\n",
              " '--': 134,\n",
              " 'But': 135,\n",
              " 'agreed': 136,\n",
              " 'review': 137,\n",
              " 'his': 138,\n",
              " 'standing': 139,\n",
              " 'mational': 140,\n",
              " 'officials': 141,\n",
              " 'questioned': 142,\n",
              " 'justified': 143,\n",
              " 'as': 144,\n",
              " 'there': 145,\n",
              " 'only': 146,\n",
              " 'slight': 147,\n",
              " 'risk': 148,\n",
              " 'Spanish': 149,\n",
              " 'Minister': 150,\n",
              " 'Loyola': 151,\n",
              " 'de': 152,\n",
              " 'Palacio': 153,\n",
              " 'had': 154,\n",
              " 'earlier': 155,\n",
              " 'accused': 156,\n",
              " 'at': 157,\n",
              " 'an': 158,\n",
              " 'farm': 159,\n",
              " 'ministers': 160,\n",
              " \"'\": 161,\n",
              " 'meeting': 162,\n",
              " 'of': 163,\n",
              " 'causing': 164,\n",
              " 'unjustified': 165,\n",
              " 'alarm': 166,\n",
              " 'through': 167,\n",
              " 'dangerous': 168,\n",
              " 'generalisation': 169,\n",
              " 'Only': 170,\n",
              " 'backed': 171,\n",
              " 'multidisciplinary': 172,\n",
              " 'committees': 173,\n",
              " 'are': 174,\n",
              " 'due': 175,\n",
              " 're-examine': 176,\n",
              " 'issue': 177,\n",
              " 'early': 178,\n",
              " 'next': 179,\n",
              " 'make': 180,\n",
              " 'recommendations': 181,\n",
              " 'senior': 182,\n",
              " 'Sheep': 183,\n",
              " 'have': 184,\n",
              " 'long': 185,\n",
              " 'been': 186,\n",
              " 'known': 187,\n",
              " 'scrapie': 188,\n",
              " 'brain-wasting': 189,\n",
              " 'similar': 190,\n",
              " 'which': 191,\n",
              " 'is': 192,\n",
              " 'believed': 193,\n",
              " 'transferred': 194,\n",
              " 'cattle': 195,\n",
              " 'feed': 196,\n",
              " 'containing': 197,\n",
              " 'waste': 198,\n",
              " 'farmers': 199,\n",
              " 'denied': 200,\n",
              " 'danger': 201,\n",
              " 'their': 202,\n",
              " 'but': 203,\n",
              " 'expressed': 204,\n",
              " 'concern': 205,\n",
              " 'government': 206,\n",
              " 'avoid': 207,\n",
              " 'might': 208,\n",
              " 'influence': 209,\n",
              " 'across': 210,\n",
              " 'Europe': 211,\n",
              " 'What': 212,\n",
              " 'extremely': 213,\n",
              " 'careful': 214,\n",
              " 'how': 215,\n",
              " 'going': 216,\n",
              " 'take': 217,\n",
              " 'lead': 218,\n",
              " 'Welsh': 219,\n",
              " 'National': 220,\n",
              " 'Farmers': 221,\n",
              " 'NFU': 222,\n",
              " 'chairman': 223,\n",
              " 'John': 224,\n",
              " 'Lloyd': 225,\n",
              " 'Jones': 226,\n",
              " 'BBC': 227,\n",
              " 'radio': 228,\n",
              " 'Bonn': 229,\n",
              " 'has': 230,\n",
              " 'led': 231,\n",
              " 'efforts': 232,\n",
              " 'public': 233,\n",
              " 'consumer': 234,\n",
              " 'confidence': 235,\n",
              " 'collapsed': 236,\n",
              " 'in': 237,\n",
              " 'March': 238,\n",
              " 'report': 239,\n",
              " 'suggested': 240,\n",
              " 'humans': 241,\n",
              " 'illness': 242,\n",
              " 'eating': 243,\n",
              " 'contaminated': 244,\n",
              " 'beef': 245,\n",
              " 'imported': 246,\n",
              " '47,600': 247,\n",
              " 'year': 248,\n",
              " 'nearly': 249,\n",
              " 'half': 250,\n",
              " 'total': 251,\n",
              " 'imports': 252,\n",
              " 'It': 253,\n",
              " 'brought': 254,\n",
              " '4,275': 255,\n",
              " 'tonnes': 256,\n",
              " 'mutton': 257,\n",
              " 'some': 258,\n",
              " '10': 259,\n",
              " 'percent': 260,\n",
              " 'overall': 261,\n",
              " 'Rare': 262,\n",
              " 'Hendrix': 263,\n",
              " 'song': 264,\n",
              " 'draft': 265,\n",
              " 'sells': 266,\n",
              " 'almost': 267,\n",
              " '$': 268,\n",
              " '17,000': 269,\n",
              " 'LONDON': 270,\n",
              " 'A': 271,\n",
              " 'rare': 272,\n",
              " 'handwritten': 273,\n",
              " 'U.S.': 274,\n",
              " 'guitar': 275,\n",
              " 'legend': 276,\n",
              " 'Jimi': 277,\n",
              " 'sold': 278,\n",
              " 'auction': 279,\n",
              " 'late': 280,\n",
              " 'musician': 281,\n",
              " 'favourite': 282,\n",
              " 'possessions': 283,\n",
              " 'Florida': 284,\n",
              " 'restaurant': 285,\n",
              " 'paid': 286,\n",
              " '10,925': 287,\n",
              " 'pounds': 288,\n",
              " '16,935': 289,\n",
              " 'Ai': 290,\n",
              " 'no': 291,\n",
              " 'telling': 292,\n",
              " 'penned': 293,\n",
              " 'piece': 294,\n",
              " 'London': 295,\n",
              " 'hotel': 296,\n",
              " 'stationery': 297,\n",
              " '1966': 298,\n",
              " 'At': 299,\n",
              " 'end': 300,\n",
              " 'January': 301,\n",
              " '1967': 302,\n",
              " 'concert': 303,\n",
              " 'English': 304,\n",
              " 'city': 305,\n",
              " 'Nottingham': 306,\n",
              " 'he': 307,\n",
              " 'threw': 308,\n",
              " 'sheet': 309,\n",
              " 'paper': 310,\n",
              " 'into': 311,\n",
              " 'audience': 312,\n",
              " 'where': 313,\n",
              " 'retrieved': 314,\n",
              " 'fan': 315,\n",
              " 'Buyers': 316,\n",
              " 'also': 317,\n",
              " 'snapped': 318,\n",
              " 'up': 319,\n",
              " '16': 320,\n",
              " 'items': 321,\n",
              " 'were': 322,\n",
              " 'put': 323,\n",
              " 'former': 324,\n",
              " 'girlfriend': 325,\n",
              " 'Kathy': 326,\n",
              " 'Etchingham': 327,\n",
              " 'who': 328,\n",
              " 'lived': 329,\n",
              " 'him': 330,\n",
              " '1969': 331,\n",
              " 'They': 332,\n",
              " 'included': 333,\n",
              " 'black': 334,\n",
              " 'lacquer': 335,\n",
              " 'mother': 336,\n",
              " 'pearl': 337,\n",
              " 'inlaid': 338,\n",
              " 'box': 339,\n",
              " 'used': 340,\n",
              " 'store': 341,\n",
              " 'drugs': 342,\n",
              " 'anonymous': 343,\n",
              " 'Australian': 344,\n",
              " 'purchaser': 345,\n",
              " 'bought': 346,\n",
              " '5,060': 347,\n",
              " '7,845': 348,\n",
              " 'guitarist': 349,\n",
              " 'died': 350,\n",
              " 'overdose': 351,\n",
              " '1970': 352,\n",
              " 'aged': 353,\n",
              " '27': 354,\n",
              " 'China': 355,\n",
              " 'says': 356,\n",
              " 'Taiwan': 357,\n",
              " 'spoils': 358,\n",
              " 'atmosphere': 359,\n",
              " 'talks': 360,\n",
              " 'BEIJING': 361,\n",
              " 'Taipei': 362,\n",
              " 'spoiling': 363,\n",
              " 'resumption': 364,\n",
              " 'Strait': 365,\n",
              " 'visit': 366,\n",
              " 'Ukraine': 367,\n",
              " 'Taiwanese': 368,\n",
              " 'Vice': 369,\n",
              " 'President': 370,\n",
              " 'Lien': 371,\n",
              " 'Chan': 372,\n",
              " 'this': 373,\n",
              " 'week': 374,\n",
              " 'infuriated': 375,\n",
              " 'Beijing': 376,\n",
              " 'Speaking': 377,\n",
              " 'hours': 378,\n",
              " 'Chinese': 379,\n",
              " 'state': 380,\n",
              " 'media': 381,\n",
              " 'time': 382,\n",
              " 'right': 383,\n",
              " 'engage': 384,\n",
              " 'political': 385,\n",
              " 'Foreign': 386,\n",
              " 'Ministry': 387,\n",
              " 'Shen': 388,\n",
              " 'Guofang': 389,\n",
              " 'Reuters': 390,\n",
              " ':': 391,\n",
              " 'necessary': 392,\n",
              " 'opening': 393,\n",
              " 'disrupted': 394,\n",
              " 'authorities': 395,\n",
              " 'State': 396,\n",
              " 'quoted': 397,\n",
              " 'top': 398,\n",
              " 'negotiator': 399,\n",
              " 'Tang': 400,\n",
              " 'Shubei': 401,\n",
              " 'visiting': 402,\n",
              " 'group': 403,\n",
              " 'rivals': 404,\n",
              " 'hold': 405,\n",
              " 'Now': 406,\n",
              " 'two': 407,\n",
              " 'sides': 408,\n",
              " '...': 409,\n",
              " 'hostility': 410,\n",
              " 'overseas': 411,\n",
              " 'edition': 412,\n",
              " 'People': 413,\n",
              " 'Daily': 414,\n",
              " 'saying': 415,\n",
              " 'foreign': 416,\n",
              " 'ministry': 417,\n",
              " 'Television': 418,\n",
              " 'interview': 419,\n",
              " 'read': 420,\n",
              " 'comments': 421,\n",
              " 'gave': 422,\n",
              " 'details': 423,\n",
              " 'why': 424,\n",
              " 'considered': 425,\n",
              " 'considers': 426,\n",
              " 'renegade': 427,\n",
              " 'province': 428,\n",
              " 'opposed': 429,\n",
              " 'all': 430,\n",
              " 'gain': 431,\n",
              " 'greater': 432,\n",
              " 'international': 433,\n",
              " 'recognition': 434,\n",
              " 'rival': 435,\n",
              " 'island': 436,\n",
              " 'practical': 437,\n",
              " 'steps': 438,\n",
              " 'towards': 439,\n",
              " 'goal': 440,\n",
              " 'Consultations': 441,\n",
              " 'held': 442,\n",
              " 'set': 443,\n",
              " 'format': 444,\n",
              " 'official': 445,\n",
              " 'Xinhua': 446,\n",
              " 'agency': 447,\n",
              " 'executive': 448,\n",
              " 'vice': 449,\n",
              " 'Association': 450,\n",
              " 'Relations': 451,\n",
              " 'Across': 452,\n",
              " 'Straits': 453,\n",
              " 'July': 454,\n",
              " 'car': 455,\n",
              " 'registrations': 456,\n",
              " '14.2': 457,\n",
              " 'pct': 458,\n",
              " 'yr': 459,\n",
              " '/': 460,\n",
              " 'FRANKFURT': 461,\n",
              " 'first-time': 462,\n",
              " 'motor': 463,\n",
              " 'vehicles': 464,\n",
              " 'jumped': 465,\n",
              " 'year-earlier': 466,\n",
              " 'period': 467,\n",
              " 'Federal': 468,\n",
              " 'office': 469,\n",
              " '356,725': 470,\n",
              " 'new': 471,\n",
              " 'cars': 472,\n",
              " 'registered': 473,\n",
              " '1996': 474,\n",
              " '304,850': 475,\n",
              " 'passenger': 476,\n",
              " '15,613': 477,\n",
              " 'trucks': 478,\n",
              " 'figures': 479,\n",
              " 'represent': 480,\n",
              " '13.6': 481,\n",
              " 'increase': 482,\n",
              " '2.2': 483,\n",
              " 'decline': 484,\n",
              " '1995': 485,\n",
              " 'Motor-bike': 486,\n",
              " 'registration': 487,\n",
              " 'rose': 488,\n",
              " '32.7': 489,\n",
              " 'growth': 490,\n",
              " 'partly': 491,\n",
              " 'increased': 492,\n",
              " 'number': 493,\n",
              " 'Germans': 494,\n",
              " 'buying': 495,\n",
              " 'abroad': 496,\n",
              " 'while': 497,\n",
              " 'manufacturers': 498,\n",
              " 'domestic': 499,\n",
              " 'demand': 500,\n",
              " 'weak': 501,\n",
              " 'federal': 502,\n",
              " 'Almost': 503,\n",
              " 'posted': 504,\n",
              " 'gains': 505,\n",
              " 'numbers': 506,\n",
              " 'Volkswagen': 507,\n",
              " 'AG': 508,\n",
              " 'won': 509,\n",
              " '77,719': 510,\n",
              " 'slightly': 511,\n",
              " 'more': 512,\n",
              " 'quarter': 513,\n",
              " 'Opel': 514,\n",
              " 'together': 515,\n",
              " 'General': 516,\n",
              " 'Motors': 517,\n",
              " 'came': 518,\n",
              " 'second': 519,\n",
              " 'place': 520,\n",
              " '49,269': 521,\n",
              " '16.4': 522,\n",
              " 'figure': 523,\n",
              " 'Third': 524,\n",
              " 'Ford': 525,\n",
              " '35,563': 526,\n",
              " 'or': 527,\n",
              " '11.7': 528,\n",
              " 'Seat': 529,\n",
              " 'Porsche': 530,\n",
              " 'fewer': 531,\n",
              " 'compared': 532,\n",
              " '3,420': 533,\n",
              " '5522': 534,\n",
              " 'fell': 535,\n",
              " '554': 536,\n",
              " '643': 537,\n",
              " 'GREEK': 538,\n",
              " 'SOCIALISTS': 539,\n",
              " 'GIVE': 540,\n",
              " 'GREEN': 541,\n",
              " 'LIGHT': 542,\n",
              " 'TO': 543,\n",
              " 'PM': 544,\n",
              " 'FOR': 545,\n",
              " 'ELECTIONS': 546,\n",
              " 'ATHENS': 547,\n",
              " 'Greek': 548,\n",
              " 'socialist': 549,\n",
              " 'party': 550,\n",
              " 'bureau': 551,\n",
              " 'green': 552,\n",
              " 'light': 553,\n",
              " 'Prime': 554,\n",
              " 'Costas': 555,\n",
              " 'Simitis': 556,\n",
              " 'snap': 557,\n",
              " 'elections': 558,\n",
              " 'its': 559,\n",
              " 'general': 560,\n",
              " 'secretary': 561,\n",
              " 'Skandalidis': 562,\n",
              " 'reporters': 563,\n",
              " 'announcement': 564,\n",
              " 'cabinet': 565,\n",
              " 'later': 566,\n",
              " 'Dimitris': 567,\n",
              " 'Kontogiannis': 568,\n",
              " 'Athens': 569,\n",
              " 'Newsroom': 570,\n",
              " '+301': 571,\n",
              " '3311812-4': 572,\n",
              " 'BayerVB': 573,\n",
              " 'sets': 574,\n",
              " 'C$': 575,\n",
              " '100': 576,\n",
              " 'million': 577,\n",
              " 'six-year': 578,\n",
              " 'bond': 579,\n",
              " 'following': 580,\n",
              " 'announced': 581,\n",
              " 'manager': 582,\n",
              " 'Toronto': 583,\n",
              " 'Dominion': 584,\n",
              " 'BORROWER': 585,\n",
              " 'BAYERISCHE': 586,\n",
              " 'VEREINSBANK': 587,\n",
              " 'AMT': 588,\n",
              " 'MLN': 589,\n",
              " 'COUPON': 590,\n",
              " '6.625': 591,\n",
              " 'MATURITY': 592,\n",
              " '24.SEP.02': 593,\n",
              " 'TYPE': 594,\n",
              " 'STRAIGHT': 595,\n",
              " 'ISS': 596,\n",
              " 'PRICE': 597,\n",
              " '100.92': 598,\n",
              " 'PAY': 599,\n",
              " 'DATE': 600,\n",
              " '24.SEP.96': 601,\n",
              " 'FULL': 602,\n",
              " 'FEES': 603,\n",
              " '1.875': 604,\n",
              " 'REOFFER': 605,\n",
              " '99.32': 606,\n",
              " 'SPREAD': 607,\n",
              " '+20': 608,\n",
              " 'BP': 609,\n",
              " 'MOODY': 610,\n",
              " 'AA1': 611,\n",
              " 'LISTING': 612,\n",
              " 'LUX': 613,\n",
              " 'FREQ': 614,\n",
              " '=': 615,\n",
              " 'S&P': 616,\n",
              " 'DENOMS': 617,\n",
              " 'K': 618,\n",
              " '1-10-100': 619,\n",
              " 'SALE': 620,\n",
              " 'LIMITS': 621,\n",
              " 'US': 622,\n",
              " 'UK': 623,\n",
              " 'CA': 624,\n",
              " 'NEG': 625,\n",
              " 'PLG': 626,\n",
              " 'NO': 627,\n",
              " 'CRS': 628,\n",
              " 'DEFLT': 629,\n",
              " 'FORCE': 630,\n",
              " 'MAJ': 631,\n",
              " 'GOV': 632,\n",
              " 'LAW': 633,\n",
              " 'GERMAN': 634,\n",
              " 'HOME': 635,\n",
              " 'CTRY': 636,\n",
              " 'TAX': 637,\n",
              " 'PROVS': 638,\n",
              " 'STANDARD': 639,\n",
              " 'MGT': 640,\n",
              " 'UND': 641,\n",
              " '0.275': 642,\n",
              " 'SELL': 643,\n",
              " 'CONC': 644,\n",
              " '1.60': 645,\n",
              " 'PRAECIP': 646,\n",
              " 'UNDERLYING': 647,\n",
              " 'GOVT': 648,\n",
              " 'BOND': 649,\n",
              " '7.0': 650,\n",
              " 'PCT': 651,\n",
              " 'SEPT': 652,\n",
              " '2001': 653,\n",
              " 'NOTES': 654,\n",
              " 'IS': 655,\n",
              " 'JOINT': 656,\n",
              " 'LEAD': 657,\n",
              " 'MANAGER': 658,\n",
              " '+44': 659,\n",
              " '171': 660,\n",
              " '542': 661,\n",
              " '7658': 662,\n",
              " 'Venantius': 663,\n",
              " '300': 664,\n",
              " '1999': 665,\n",
              " 'FRN': 666,\n",
              " 'floating-rate': 667,\n",
              " 'Lehman': 668,\n",
              " 'Brothers': 669,\n",
              " 'International': 670,\n",
              " 'VENANTIUS': 671,\n",
              " 'AB': 672,\n",
              " 'SWEDISH': 673,\n",
              " 'NATIONAL': 674,\n",
              " 'MORTGAGE': 675,\n",
              " 'AGENCY': 676,\n",
              " '-': 677,\n",
              " '12.5': 678,\n",
              " '21.JAN.99': 679,\n",
              " 'BASE': 680,\n",
              " '3M': 681,\n",
              " 'LIBOR': 682,\n",
              " 'S23.SEP.96': 683,\n",
              " 'LAST': 684,\n",
              " 'AA3': 685,\n",
              " '99.956': 686,\n",
              " 'AA+': 687,\n",
              " 'S': 688,\n",
              " 'SHORT': 689,\n",
              " 'FIRST': 690,\n",
              " 'JP': 691,\n",
              " 'FR': 692,\n",
              " 'YES': 693,\n",
              " 'IPMA': 694,\n",
              " '2': 695,\n",
              " 'ENGLISH': 696,\n",
              " 'SWEDEN': 697,\n",
              " '5': 698,\n",
              " 'ISSUED': 699,\n",
              " 'OFF': 700,\n",
              " 'EMTN': 701,\n",
              " 'PROGRAMME': 702,\n",
              " '8863': 703,\n",
              " 'Port': 704,\n",
              " 'update': 705,\n",
              " 'Syria': 706,\n",
              " 'Lloyds': 707,\n",
              " 'Shipping': 708,\n",
              " 'Intelligence': 709,\n",
              " 'Service': 710,\n",
              " 'LATTAKIA': 711,\n",
              " 'Aug': 712,\n",
              " 'waiting': 713,\n",
              " 'Lattakia': 714,\n",
              " 'Tartous': 715,\n",
              " 'presently': 716,\n",
              " '24': 717,\n",
              " 'Israel': 718,\n",
              " 'plays': 719,\n",
              " 'down': 720,\n",
              " 'fears': 721,\n",
              " 'war': 722,\n",
              " 'Colleen': 723,\n",
              " 'Siegel': 724,\n",
              " 'JERUSALEM': 725,\n",
              " 'outgoing': 726,\n",
              " 'peace': 727,\n",
              " 'current': 728,\n",
              " 'tensions': 729,\n",
              " 'between': 730,\n",
              " 'appeared': 731,\n",
              " 'storm': 732,\n",
              " 'teacup': 733,\n",
              " 'Itamar': 734,\n",
              " 'Rabinovich': 735,\n",
              " 'ambassador': 736,\n",
              " 'Washington': 737,\n",
              " 'conducted': 738,\n",
              " 'unfruitful': 739,\n",
              " 'negotiations': 740,\n",
              " 'Radio': 741,\n",
              " 'looked': 742,\n",
              " 'like': 743,\n",
              " 'Damascus': 744,\n",
              " 'wanted': 745,\n",
              " 'talk': 746,\n",
              " 'rather': 747,\n",
              " 'fight': 748,\n",
              " 'appears': 749,\n",
              " 'me': 750,\n",
              " 'Syrian': 751,\n",
              " 'priority': 752,\n",
              " 'still': 753,\n",
              " 'negotiate': 754,\n",
              " 'Syrians': 755,\n",
              " 'confused': 756,\n",
              " 'they': 757,\n",
              " 'definitely': 758,\n",
              " 'tense': 759,\n",
              " 'assessment': 760,\n",
              " 'here': 761,\n",
              " 'essentially': 762,\n",
              " 'winding': 763,\n",
              " 'term': 764,\n",
              " 'will': 765,\n",
              " 'replaced': 766,\n",
              " 'Eliahu': 767,\n",
              " 'Ben-Elissar': 768,\n",
              " 'Israeli': 769,\n",
              " 'envoy': 770,\n",
              " 'Egypt': 771,\n",
              " 'right-wing': 772,\n",
              " 'Likud': 773,\n",
              " 'politician': 774,\n",
              " 'sent': 775,\n",
              " 'message': 776,\n",
              " 'via': 777,\n",
              " 'committed': 778,\n",
              " 'open': 779,\n",
              " 'without': 780,\n",
              " 'preconditions': 781,\n",
              " 'slammed': 782,\n",
              " 'creating': 783,\n",
              " 'what': 784,\n",
              " 'called': 785,\n",
              " 'launching': 786,\n",
              " 'hysterical': 787,\n",
              " 'campaign': 788,\n",
              " 'against': 789,\n",
              " 'television': 790,\n",
              " 'reported': 791,\n",
              " 'recently': 792,\n",
              " 'test': 793,\n",
              " 'fired': 794,\n",
              " 'missile': 795,\n",
              " 'arms': 796,\n",
              " 'purchases': 797,\n",
              " 'defensive': 798,\n",
              " 'purposes': 799,\n",
              " 'Hafez': 800,\n",
              " 'al-': 801,\n",
              " 'Assad': 802,\n",
              " 'ready': 803,\n",
              " 'enter': 804,\n",
              " 'David': 805,\n",
              " 'Levy': 806,\n",
              " 'Tension': 807,\n",
              " 'mounted': 808,\n",
              " 'since': 809,\n",
              " 'Benjamin': 810,\n",
              " 'Netanyahu': 811,\n",
              " 'took': 812,\n",
              " 'June': 813,\n",
              " 'vowing': 814,\n",
              " 'retain': 815,\n",
              " 'Golan': 816,\n",
              " 'Heights': 817,\n",
              " 'captured': 818,\n",
              " 'Middle': 819,\n",
              " 'East': 820,\n",
              " 'Israeli-Syrian': 821,\n",
              " 'deadlocked': 822,\n",
              " 'over': 823,\n",
              " '1991': 824,\n",
              " 'despite': 825,\n",
              " 'previous': 826,\n",
              " 'willingness': 827,\n",
              " 'concessions': 828,\n",
              " 'Peace': 829,\n",
              " 'February': 830,\n",
              " 'voices': 831,\n",
              " 'coming': 832,\n",
              " 'out': 833,\n",
              " 'bad': 834,\n",
              " 'not': 835,\n",
              " 'good': 836,\n",
              " 'full': 837,\n",
              " 'expressions': 838,\n",
              " 'declarations': 839,\n",
              " 'must': 840,\n",
              " 'worrying': 841,\n",
              " 'artificial': 842,\n",
              " 'very': 843,\n",
              " 'those': 844,\n",
              " 'spread': 845,\n",
              " 'become': 846,\n",
              " 'prisoners': 847,\n",
              " 'expect': 848,\n",
              " 'face': 849,\n",
              " 'answer': 850,\n",
              " 'our': 851,\n",
              " 'want': 852,\n",
              " 'God': 853,\n",
              " 'forbid': 854,\n",
              " 'No': 855,\n",
              " 'one': 856,\n",
              " 'benefits': 857,\n",
              " 'wars': 858,\n",
              " 'Channel': 859,\n",
              " 'Two': 860,\n",
              " 'calming': 861,\n",
              " 'signal': 862,\n",
              " 'source': 863,\n",
              " 'spokesmen': 864,\n",
              " 'confirm': 865,\n",
              " 'messages': 866,\n",
              " 'reassure': 867,\n",
              " 'Cairo': 868,\n",
              " 'United': 869,\n",
              " 'States': 870,\n",
              " 'Moscow': 871,\n",
              " 'Polish': 872,\n",
              " 'diplomat': 873,\n",
              " 'denies': 874,\n",
              " 'nurses': 875,\n",
              " 'stranded': 876,\n",
              " 'Libya': 877,\n",
              " 'TUNIS': 878,\n",
              " 'tabloid': 879,\n",
              " 'refusing': 880,\n",
              " 'exit': 881,\n",
              " 'visas': 882,\n",
              " 'trying': 883,\n",
              " 'return': 884,\n",
              " 'home': 885,\n",
              " 'working': 886,\n",
              " 'North': 887,\n",
              " 'African': 888,\n",
              " 'country': 889,\n",
              " 'This': 890,\n",
              " 'true': 891,\n",
              " 'Up': 892,\n",
              " 'today': 893,\n",
              " 'knowledge': 894,\n",
              " 'nurse': 895,\n",
              " 'kept': 896,\n",
              " 'her': 897,\n",
              " 'received': 898,\n",
              " 'complaint': 899,\n",
              " 'embassy': 900,\n",
              " 'charge': 901,\n",
              " \"d'affaires\": 902,\n",
              " 'Tripoli': 903,\n",
              " 'Tadeusz': 904,\n",
              " 'Awdankiewicz': 905,\n",
              " 'telephone': 906,\n",
              " 'Poland': 907,\n",
              " 'labour': 908,\n",
              " 'would': 909,\n",
              " 'send': 910,\n",
              " 'team': 911,\n",
              " 'investigate': 912,\n",
              " 'probe': 913,\n",
              " 'prompted': 914,\n",
              " 'complaining': 915,\n",
              " 'about': 916,\n",
              " 'work': 917,\n",
              " 'non-payment': 918,\n",
              " 'salaries': 919,\n",
              " 'estimated': 920,\n",
              " '800': 921,\n",
              " 'Iranian': 922,\n",
              " 'opposition': 923,\n",
              " 'leaders': 924,\n",
              " 'meet': 925,\n",
              " 'Baghdad': 926,\n",
              " 'Hassan': 927,\n",
              " 'Hafidh': 928,\n",
              " 'BAGHDAD': 929,\n",
              " 'An': 930,\n",
              " 'exile': 931,\n",
              " 'based': 932,\n",
              " 'Iraq': 933,\n",
              " 'vowed': 934,\n",
              " 'extend': 935,\n",
              " 'Iran': 936,\n",
              " 'Kurdish': 937,\n",
              " 'rebels': 938,\n",
              " 'attacked': 939,\n",
              " 'troops': 940,\n",
              " 'deep': 941,\n",
              " 'inside': 942,\n",
              " 'Mujahideen': 943,\n",
              " 'Khalq': 944,\n",
              " 'statement': 945,\n",
              " 'leader': 946,\n",
              " 'Massoud': 947,\n",
              " 'Rajavi': 948,\n",
              " 'met': 949,\n",
              " 'Secretary-General': 950,\n",
              " 'Kurdistan': 951,\n",
              " 'Democratic': 952,\n",
              " 'Party': 953,\n",
              " 'KDPI': 954,\n",
              " 'Rastegar': 955,\n",
              " 'voiced': 956,\n",
              " 'rebel': 957,\n",
              " 'Kurds': 958,\n",
              " 'emphasised': 959,\n",
              " 'Resistance': 960,\n",
              " 'continue': 961,\n",
              " 'stand': 962,\n",
              " 'side': 963,\n",
              " 'compatriots': 964,\n",
              " 'resistance': 965,\n",
              " 'movement': 966,\n",
              " 'signals': 967,\n",
              " 'level': 968,\n",
              " 'cooperation': 969,\n",
              " 'oppositions': 970,\n",
              " 'heavily': 971,\n",
              " 'bombarded': 972,\n",
              " 'targets': 973,\n",
              " 'northern': 974,\n",
              " 'pursuit': 975,\n",
              " 'guerrillas': 976,\n",
              " 'Iraqi': 977,\n",
              " 'areas': 978,\n",
              " 'outside': 979,\n",
              " 'control': 980,\n",
              " 'bordering': 981,\n",
              " 'Patriotic': 982,\n",
              " 'PUK': 983,\n",
              " 'KDP': 984,\n",
              " 'main': 985,\n",
              " 'factions': 986,\n",
              " 'forces': 987,\n",
              " 'ousted': 988,\n",
              " 'Kuwait': 989,\n",
              " 'Gulf': 990,\n",
              " 'War': 991,\n",
              " 'Clashes': 992,\n",
              " 'parties': 993,\n",
              " 'broke': 994,\n",
              " 'weekend': 995,\n",
              " 'most': 996,\n",
              " 'serious': 997,\n",
              " 'fighting': 998,\n",
              " 'U.S.-sponsored': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define the PyTorch Dataset:\n",
        "- It is common while building applications with PyTorch to use [Datasets and DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "\n",
        "We first define a Dataset by defining a custom class class (with Dataset as superclass). This class will reimplement at least three core methods:\n",
        "- `__init__` to initialize the variables used to store the actual data and labels\n",
        "-` __len__` methods to determine the length of the dataset (based on the variabels declared in the __init__ method)\n",
        "- `__getitem__` methods that will be called by the DataLoader object automatically, it must return a single sample of the dataset along with its label\n",
        "\n",
        "Subsequently, we will define our DataLoader, which in turn needs to arrange batches of data.\n"
      ],
      "metadata": {
        "id": "xjw4po7a-uNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, data, word2idx, tag2idx):\n",
        "        self.data = data\n",
        "        self.word2idx = word2idx\n",
        "        self.tag2idx = tag2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sent = self.data[idx]\n",
        "        words = [token[\"text\"] for token in sent]\n",
        "        tags = [token[\"ner_tag\"] for token in sent]\n",
        "        # Mapping words to indices, using <UNK> if the word is not present in the vocabulary\n",
        "        word_indices = [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in words]\n",
        "        tag_indices = [self.tag2idx[tag] for tag in tags]\n",
        "        return torch.tensor(word_indices, dtype=torch.long), torch.tensor(tag_indices, dtype=torch.long)\n",
        "\n",
        "# Creazione dei dataset\n",
        "train_dataset = NERDataset(train_data, word2idx, tag2idx)\n",
        "valid_dataset = NERDataset(valid_data, word2idx, tag2idx)\n",
        "test_dataset  = NERDataset(test_data, word2idx, tag2idx)"
      ],
      "metadata": {
        "id": "9K0K6KuHAXFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define a DataLoader, having already define the DatasetObject, we need to define our custom collate function:\n",
        "- `collate_fn` is a function that the DataLoader is calling everytime it needs to build a new batch of data. This is done because we need a custom function which pads sequences.\n"
      ],
      "metadata": {
        "id": "67W8rJefA1li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    # batch: list of tuples (word_tensor, tag_tensor)\n",
        "    # Get input sentences\n",
        "    sentences = [item[0] for item in batch]\n",
        "    # Get labels\n",
        "    tags = [item[1] for item in batch]\n",
        "    # Get maximum length in the batch\n",
        "    lengths = [len(s) for s in sentences]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    # Pad shorter sentences to let the input tensors all have the same size\n",
        "    padded_sentences = []\n",
        "    padded_tags = []\n",
        "    for s, t in zip(sentences, tags):\n",
        "        pad_len = max_len - len(s)\n",
        "        # Padding uses index 0 both for words and labels\n",
        "        padded_sentences.append(torch.cat([s, torch.zeros(pad_len, dtype=torch.long)]))\n",
        "        padded_tags.append(torch.cat([t, torch.zeros(pad_len, dtype=torch.long)]))\n",
        "\n",
        "    #\n",
        "    return torch.stack(padded_sentences), torch.stack(padded_tags), lengths\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "0FgmlDu8A4xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NwBTbAlXkPQ"
      },
      "source": [
        "### Defining and training the RNN model for NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKmcrDFTXkPQ"
      },
      "source": [
        "We start by importing the required modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "5NeKieQnCsFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_NER(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags):\n",
        "        super(BiLSTM_NER, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Bidirectional LSTM; we set batch_first=True to have input like [batch, seq_len, embedding_dim]\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        # Fully connected layer to map hidden state coming from LSTM to output labels\n",
        "        # (the hidden state is a concatenation of two LSTM outputs since it is bidirectional)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_tags)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len]\n",
        "        embeds = self.embedding(x)        # embeds: [batch_size, seq_len, embedding_dim]\n",
        "        lstm_out, _ = self.lstm(embeds)   # lstm_out: [batch_size, seq_len, hidden_dim*2]\n",
        "        logits = self.fc(lstm_out)        # logits: [batch_size, seq_len, num_tags]\n",
        "        return logits"
      ],
      "metadata": {
        "id": "zmctap4tCufE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametri del modello\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "CVRdsjaxCw-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model"
      ],
      "metadata": {
        "id": "2VM9PiFdM2gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM_NER(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, num_tags)"
      ],
      "metadata": {
        "id": "vZLJs0eLM31w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define loss and optimizer:\n",
        "- Note that we need to pay attention not computing the loss for padding tokens!"
      ],
      "metadata": {
        "id": "C4vR9yrIM4kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We ignore padding token to calculate the loss\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "cJ6fSn3dCzLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's identify the device we are using"
      ],
      "metadata": {
        "id": "bIaTvvQUOHPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHAAK33POCoR",
        "outputId": "7497d015-712a-4107-940c-46f86560676c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move to model to the available device"
      ],
      "metadata": {
        "id": "XR0PlOeXONHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qFoUnLujOMfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop"
      ],
      "metadata": {
        "id": "izCbLCbMC2rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Set the model in training mode\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for inputs, targets, lengths in tqdm(train_loader):\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "        # Move input and output to target device\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # Run input though the model\n",
        "        outputs = model(inputs)  # outputs: [batch, seq_len, num_tags]\n",
        "        # Flat batch and seq_len dimensions to compute the loss\n",
        "        outputs = outputs.view(-1, num_tags)\n",
        "        targets = targets.view(-1)\n",
        "        loss = criterion(outputs, targets)\n",
        "        # Call the backward pass\n",
        "        loss.backward()\n",
        "        # Tell the optimizer to do a step forward in the training\n",
        "        optimizer.step()\n",
        "        # Record loss logs\n",
        "        epoch_loss += loss.item()\n",
        "        history.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R44xYtjNC5GP",
        "outputId": "e57acd85-f22a-465b-ae51-ed9c4564fe9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:34<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.6344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:34<00:00, 12.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 - Loss: 0.3239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:34<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 - Loss: 0.2056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:33<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 - Loss: 0.1372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:32<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 - Loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:32<00:00, 13.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 - Loss: 0.0589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:40<00:00, 10.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 - Loss: 0.0365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:32<00:00, 13.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 - Loss: 0.0216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:33<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 - Loss: 0.0121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 439/439 [00:32<00:00, 13.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 - Loss: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(len(history)), history)\n",
        "plt.xlabel('Update step')\n",
        "plt.ylabel('Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "QZZK7ruyUhRe",
        "outputId": "86d6455a-a81e-4c9c-960f-f957a848f460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "UNnlXnRuC8lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_loss = 0\n",
        "    for inputs, targets, lengths in valid_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.view(-1, num_tags)\n",
        "        targets = targets.view(-1)\n",
        "        loss = criterion(outputs, targets)\n",
        "        total_loss += loss.item()\n",
        "    print(\"Validation Loss:\", total_loss / len(valid_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYPGHJXPC9do",
        "outputId": "3778ab77-68ba-4a02-dbd5-d04bd975422a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.25658097834207627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test inference"
      ],
      "metadata": {
        "id": "MuBlZl8uDBR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an inverse dictionary to decode labels (idx -> tag)\n",
        "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
        "# If we also want to decode words, we need to build an inverse dictionary also for words\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}"
      ],
      "metadata": {
        "id": "TnNknBF3O2hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esempio di inference e decodifica per il Test Set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, targets, lengths in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # Run the model with the current input\n",
        "        outputs = model(inputs)\n",
        "        # Get the tag with the highest probability for each token\n",
        "        predicted_tags = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "        # Decoding and printing predicted ner tags for every sample in the batch\n",
        "        for i in range(len(inputs)):\n",
        "          seq_len = lengths[i]\n",
        "\n",
        "          # Extract original indices (not considering padding)\n",
        "          sentence_indices = inputs[i][:seq_len].tolist()\n",
        "          true_tag_indices = targets[i][:seq_len].tolist()\n",
        "          pred_tag_indices = predicted_tags[i][:seq_len].tolist()\n",
        "\n",
        "          # Deconde indices in words and tags\n",
        "          sentence_tokens = [idx2word.get(idx, \"<UNK>\") for idx in sentence_indices]\n",
        "          true_tags = [idx2tag[idx] for idx in true_tag_indices]\n",
        "          pred_tags = [idx2tag[idx] for idx in pred_tag_indices]\n",
        "\n",
        "          print(\"Original Sentence: \", sentence_tokens)\n",
        "          print(\"Ground Truth NER Tags:\", true_tags)\n",
        "          print(\"Predicted NER Tags:  \", pred_tags)\n",
        "          print(\"-\" * 50)\n",
        "        break  # Run only the first batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWDUdbkhDD8g",
        "outputId": "41b95470-97d4-4df6-bde8-d51e4a1b1307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence:  ['SOCCER', '-', '<UNK>', '<UNK>', '<UNK>', 'WIN', ',', 'CHINA', 'IN', '<UNK>', 'DEFEAT', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'B-MISC', 'B-MISC', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', '<UNK>']\n",
            "Ground Truth NER Tags: ['B-PER', 'I-PER']\n",
            "Predicted NER Tags:   ['B-LOC', 'B-LOC']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', ',', 'United', 'Arab', 'Emirates', '<UNK>']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', '<UNK>', '.']\n",
            "Ground Truth NER Tags: ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "Predicted NER Tags:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['China', 'controlled', 'most', 'of', 'the', 'match', 'and', 'saw', 'several', 'chances', 'missed', 'until', 'the', '78th', 'minute', 'when', '<UNK>', 'striker', '<UNK>', '<UNK>', 'took', 'advantage', 'of', 'a', '<UNK>', 'defensive', 'header', 'to', 'lob', 'the', 'ball', 'over', 'the', 'advancing', 'Chinese', 'keeper', 'and', 'into', 'an', 'empty', 'net', '.']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', '<UNK>', 'made', 'sure', 'of', 'the', 'win', 'in', 'injury', 'time', ',', 'hitting', 'an', '<UNK>', 'left', 'foot', 'shot', 'from', 'just', 'outside', 'the', 'area', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['The', 'former', 'Soviet', 'republic', 'was', 'playing', 'in', 'an', 'Asian', 'Cup', 'finals', 'tie', 'for', 'the', 'first', 'time', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Despite', 'winning', 'the', 'Asian', 'Games', 'title', 'two', 'years', 'ago', ',', '<UNK>', 'are', 'in', 'the', 'finals', 'as', 'outsiders', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'B-MISC', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Two', 'goals', 'from', 'defensive', 'errors', 'in', 'the', 'last', 'six', 'minutes', 'allowed', 'Japan', 'to', 'come', 'from', 'behind', 'and', 'collect', 'all', 'three', 'points', 'from', 'their', 'opening', 'meeting', 'against', 'Syria', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', '<UNK>', 'scored', 'the', 'winner', 'in', 'the', '<UNK>', 'minute', ',', 'rising', 'to', 'head', 'a', '<UNK>', '<UNK>', 'cross', 'towards', 'the', 'Syrian', 'goal', 'which', 'goalkeeper', '<UNK>', '<UNK>', 'appeared', 'to', 'have', 'covered', 'but', 'then', 'allowed', 'to', 'slip', 'into', 'the', 'net', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['It', 'was', 'the', 'second', 'costly', 'blunder', 'by', 'Syria', 'in', 'four', 'minutes', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', 'Hassan', 'Abbas', 'rose', 'to', '<UNK>', 'a', 'long', 'ball', 'into', 'the', 'area', 'in', 'the', '84th', 'minute', 'but', 'only', 'managed', 'to', '<UNK>', 'it', 'into', 'the', 'top', 'corner', 'of', '<UNK>', \"'s\", 'goal', '.']\n",
            "Ground Truth NER Tags: ['O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', '<UNK>', 'had', 'given', 'Syria', 'the', 'lead', 'with', 'a', '<UNK>', 'header', 'in', 'the', 'seventh', 'minute', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Japan', 'then', 'laid', '<UNK>', 'to', 'the', 'Syrian', 'penalty', 'area', 'for', 'most', 'of', 'the', 'game', 'but', 'rarely', '<UNK>', 'the', 'Syrian', 'defence', '.']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', 'pulled', 'off', 'fine', '<UNK>', '<UNK>', 'they', 'did', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Japan', 'coach', '<UNK>', '<UNK>', 'said', ':', \"'\", \"'\", 'The', 'Syrian', 'own', 'goal', 'proved', 'lucky', 'for', 'us', '.']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'B-LOC', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['The', 'Syrians', 'scored', 'early', 'and', 'then', 'played', '<UNK>', 'and', 'adopted', 'long', 'balls', 'which', 'made', 'it', 'hard', 'for', 'us', '.', \"'\"]\n",
            "Ground Truth NER Tags: ['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  [\"'\"]\n",
            "Ground Truth NER Tags: ['O']\n",
            "Predicted NER Tags:   ['O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Japan', ',', '<UNK>', 'of', 'the', 'World', 'Cup', 'in', '2002', 'and', 'ranked', '20th', 'in', 'the', 'world', 'by', 'FIFA', ',', 'are', 'favourites', 'to', 'regain', 'their', 'title', 'here', '.']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'B-LOC', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', 'UAE', 'play', 'Kuwait', 'and', 'South', 'Korea', 'take', 'on', 'Indonesia', 'on', 'Saturday', 'in', 'Group', 'A', 'matches', '.']\n",
            "Ground Truth NER Tags: ['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['All', 'four', 'teams', 'are', 'level', 'with', 'one', 'point', 'each', 'from', 'one', 'game', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['RUGBY', 'UNION', '-', '<UNK>', 'BACK', 'FOR', '<UNK>', 'AFTER', 'A', 'YEAR', '.']\n",
            "Ground Truth NER Tags: ['B-ORG', 'I-ORG', 'O', 'B-PER', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-ORG', 'I-ORG', 'O', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['ROME', '<UNK>']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'I-ORG']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Italy', 'recalled', '<UNK>', '<UNK>']\n",
            "Ground Truth NER Tags: ['B-LOC', 'O', 'B-PER', 'I-PER']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'B-LOC', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['on', 'Friday', 'for', 'their', 'friendly', 'against', 'Scotland', 'at', '<UNK>', 'more', 'than', 'a', 'year', 'after', 'the', '30-year-old', 'wing', 'announced', 'he', 'was', 'retiring', 'following', 'differences', 'over', 'selection', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', ',', 'who', 'trainer', 'George', '<UNK>', 'said', 'was', 'certain', 'to', 'play', 'on', 'Saturday', 'week', ',', 'was', 'named', 'in', 'a', '<UNK>', 'squad', 'lacking', 'only', 'two', 'of', 'the', 'team', 'beaten', '<UNK>', 'by', 'England', 'at', '<UNK>', 'last', 'month', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['Stefano', '<UNK>', 'is', 'out', 'through', 'illness', 'and', '<UNK>', 'said', 'he', 'had', 'dropped', 'back', 'row', '<UNK>', '<UNK>', ',', 'who', 'had', 'been', 'recalled', 'for', 'the', 'England', 'game', 'after', 'five', 'years', 'out', 'of', 'the', 'national', 'team', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', 'announced', 'his', 'retirement', 'after', 'the', '1995', 'World', 'Cup', ',', 'where', 'he', 'took', 'issue', 'with', 'being', 'dropped', 'from', 'the', 'Italy', 'side', 'that', 'faced', 'England', 'in', 'the', 'pool', 'stages', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['<UNK>', 'said', 'he', 'had', 'approached', 'the', 'player', 'two', 'months', 'ago', 'about', 'a', 'comeback', '.']\n",
            "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['\"', 'He', 'ended', 'the', 'World', 'Cup', 'on', 'the', 'wrong', 'note', ',', '\"', '<UNK>', 'said', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-PER', 'O', 'O']\n",
            "--------------------------------------------------\n",
            "Original Sentence:  ['\"', 'I', 'thought', 'it', 'would', 'be', 'useful', 'to', 'have', 'him', 'back', 'and', 'he', 'said', 'he', 'would', 'be', 'available', '.']\n",
            "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "all_true = []\n",
        "all_pred = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, targets, lengths in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      predicted_tags = torch.argmax(outputs, dim=-1)\n",
        "      # For each sequence in the batch, collect true and predicted labels (excluding padding)\n",
        "      for i in range(len(inputs)):\n",
        "          seq_len = lengths[i]\n",
        "          true_tag_indices = targets[i][:seq_len].tolist()\n",
        "          pred_tag_indices = predicted_tags[i][:seq_len].tolist()\n",
        "          all_true.extend(true_tag_indices)\n",
        "          all_pred.extend(pred_tag_indices)\n",
        "\n",
        "# Optionally, filter out the padding index (0) if it might be present in the evaluation,\n",
        "# but since we use the actual sequence lengths, padding should not be included.\n",
        "# Create a list of target names sorted by tag index, excluding the PAD tag\n",
        "target_names = [idx2tag[idx] for idx in sorted(idx2tag.keys()) if idx != 0]\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(all_true, all_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0qbTRYDTmst",
        "outputId": "53e86e5b-ca72-4d98-e8a8-6fff3525ca94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-ORG       0.74      0.66      0.70      1661\n",
            "           O       0.98      0.95      0.96     38323\n",
            "      B-MISC       0.51      0.68      0.59       702\n",
            "       B-PER       0.82      0.58      0.68      1617\n",
            "       I-PER       0.85      0.66      0.75      1156\n",
            "       B-LOC       0.45      0.86      0.59      1668\n",
            "       I-ORG       0.48      0.74      0.58       835\n",
            "      I-MISC       0.47      0.58      0.52       216\n",
            "       I-LOC       0.61      0.61      0.61       257\n",
            "\n",
            "    accuracy                           0.90     46435\n",
            "   macro avg       0.66      0.70      0.66     46435\n",
            "weighted avg       0.92      0.90      0.91     46435\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4uE1efbqpdl3",
        "VS1PK7ifpdl5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
